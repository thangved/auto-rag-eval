{"0": {"documentation": {"title": "Dominant Resource Fairness with Meta-Types", "source": "Steven Yin, Shatian Wang, Lingyi Zhang, Christian Kroer", "docs_id": "2007.11961", "section": ["econ.TH", "cs.GT"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Dominant Resource Fairness with Meta-Types. Inspired by the recent COVID-19 pandemic, we study a generalization of the multi-resource allocation problem with heterogeneous demands and Leontief utilities. Unlike existing settings, we allow each agent to specify requirements to only accept allocations from a subset of the total supply for each resource. These requirements can take form in location constraints (e.g. A hospital can only accept volunteers who live nearby due to commute limitations). This can also model a type of substitution effect where some agents need 1 unit of resource A \\emph{or} B, both belonging to the same meta-type. But some agents specifically want A, and others specifically want B. We propose a new mechanism called Dominant Resource Fairness with Meta Types which determines the allocations by solving a small number of linear programs. The proposed method satisfies Pareto optimality, envy-freeness, strategy-proofness, and a notion of sharing incentive for our setting. To the best of our knowledge, we are the first to study this problem formulation, which improved upon existing work by capturing more constraints that often arise in real life situations. Finally, we show numerically that our method scales better to large problems than alternative approaches."}, "answer": " Here is a multi-form question on the document:\n\nQuestion: Which of the following statements is true about the Dominant Resource Fairness with Meta-Types mechanism proposed in the paper?\n\nA) It satisfies Pareto optimality and envy-freeness, but not strategy-proofness. \n\nB) It allows agents to specify requirements for only accepting allocations from a subset of resources, capturing real-life constraints.\n\nC) It scales worse to large problems compared to existing approaches.\n\nD) It does not improve upon existing work in multi-resource allocation problems.\n\nCorrect Answer: B\n\nExplanation: According to the document, the Dominant Resource Fairness with Meta-Types mechanism satisfies Pareto optimality, envy-freeness, and strategy-proofness. It also allows agents to specify subset requirements, capturing real-life constraints not modeled before. Finally, it is said to scale better to large problems than alternative approaches."}, "1": {"documentation": {"title": "Sparse Lifting of Dense Vectors: Unifying Word and Sentence\n  Representations", "source": "Wenye Li and Senyue Hao", "docs_id": "1911.01625", "section": ["cs.CL", "cs.LG"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Sparse Lifting of Dense Vectors: Unifying Word and Sentence\n  Representations. As the first step in automated natural language processing, representing words and sentences is of central importance and has attracted significant research attention. Different approaches, from the early one-hot and bag-of-words representation to more recent distributional dense and sparse representations, were proposed. Despite the successful results that have been achieved, such vectors tend to consist of uninterpretable components and face nontrivial challenge in both memory and computational requirement in practical applications. In this paper, we designed a novel representation model that projects dense word vectors into a higher dimensional space and favors a highly sparse and binary representation of word vectors with potentially interpretable components, while trying to maintain pairwise inner products between original vectors as much as possible. Computationally, our model is relaxed as a symmetric non-negative matrix factorization problem which admits a fast yet effective solution. In a series of empirical evaluations, the proposed model exhibited consistent improvement and high potential in practical applications."}, "answer": " Question: What approach did the authors propose to project dense word vectors into a higher dimensional space while trying to maintain pairwise inner products between original vectors?\n\nA) Using a symmetric non-negative matrix factorization model which admits a fast yet effective solution.\n\nB) Combining one-hot and bag-of-words representations into a single model.\n\nC) Training a neural network to learn interpretable word representations. \n\nD) Applying dimensionality reduction techniques like PCA or autoencoders.\n\nCorrect Answer: A\n\nExplanation: The passage states that the authors \"designed a novel representation model that projects dense word vectors into a higher dimensional space and favors a highly sparse and binary representation of word vectors with potentially interpretable components, while trying to maintain pairwise inner products between original vectors as much as possible.\" It further states that their model is \"relaxed as a symmetric non-negative matrix factorization problem which admits a fast yet effective solution.\" Therefore, option A is correct."}, "2": {"documentation": {"title": "Modelling System of Systems Interface Contract Behaviour", "source": "Oldrich Faldik (Mendel University, Brno, Czech Republic), Richard\n  Payne (Newcastle University, Newcastle upon Tyne, United Kingdom), John\n  Fitzgerald (Newcastle University, Newcastle upon Tyne, United Kingdom),\n  Barbora Buhnova (Masaryk University, Brno, Czech Republic)", "docs_id": "1703.07037", "section": ["cs.SE", "cs.FL"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Modelling System of Systems Interface Contract Behaviour. A key challenge in System of Systems (SoS) engineering is the analysis and maintenance of global properties under SoS evolution, and the integration of new constituent elements. There is a need to model the constituent systems composing a SoS in order to allow the analysis of emergent behaviours at the SoS boundary. The Contract pattern allows the engineer to specify constrained behaviours to which constituent systems are required to conform in order to be a part of the SoS. However, the Contract pattern faces some limitations in terms of its accessibility and suitability for verifying contract compatibility. To address these deficiencies, we propose the enrichment of the Contract pattern, which hitherto has been defined using SysML and the COMPASS Modelling Language (CML), by utilising SysML and Object Constraint Language (OCL). In addition, we examine the potential of interface automata, a notation for improving loose coupling between interfaces of constituent systems defined according to the contract, as a means of enabling the verification of contract compatibility. The approach is demonstrated using a case study in audio/video content streaming."}, "answer": " Question: Which of the following statements accurately describes a key limitation of the Contract pattern that is addressed in the paper?\n\nA) The Contract pattern lacks a formal notation for specifying constituent system behaviors, which makes it difficult to verify contract compatibility.\n\nB) The Contract pattern does not allow for the specification of system interfaces, resulting in tight coupling between constituent systems. \n\nC) The Contract pattern cannot be used to model emergent System of Systems (SoS) behaviors at the boundary.\n\nD) The Contract pattern relies solely on SysML, which limits its accessibility and suitability for formal verification.\n\nCorrect Answer: D\n\nExplanation: The passage states that the Contract pattern faces limitations in terms of its accessibility and suitability for formal verification, as it has hitherto been defined using only SysML and CML. The proposed solution is to enrich the Contract pattern by utilizing SysML and OCL, which enables formal verification of contract compatibility."}, "3": {"documentation": {"title": "Power-Constrained Trajectory Optimization for Wireless UAV Relays with\n  Random Requests", "source": "Matthew Bliss and Nicol\\`o Michelusi", "docs_id": "2002.09617", "section": ["cs.IT", "eess.SP", "math.IT"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Power-Constrained Trajectory Optimization for Wireless UAV Relays with\n  Random Requests. This paper studies the adaptive trajectory design of a rotary-wing UAV serving as a relay between ground nodes dispersed in a circular cell and generating uplink data transmissions randomly according to a Poisson process, and a central base station. We seek to minimize the expected average communication delay to service the data transmission requests, subject to an average power constraint on the mobility of the UAV. The problem is cast as a semi-Markov decision process, and it is shown that the policy exhibits a two-scale structure, which can be efficiently optimized: in the outer decision, upon starting a communication phase, and given its current radius, the UAV selects a target end radius position so as to optimally balance a trade-off between average long-term communication delay and power consumption; in the inner decision, the UAV selects its trajectory between the start radius and the selected end radius, so as to greedily minimize the delay and energy consumption to serve the current request. Numerical evaluations show that, during waiting phases, the UAV circles at some optimal radius at the most energy efficient speed, until a new request is received. Lastly, the expected average communication delay and power consumption of the optimal policy is compared to that of several heuristics, demonstrating a reduction in latency by over 50% and 20%, respectively, compared to static and mobile heuristic schemes."}, "answer": " Here is a 4-option multiple choice question on the paper:\n\nQuestion: Which of the following statements is true about the adaptive trajectory design approach proposed in the paper for a UAV serving as a wireless relay between ground nodes and a base station?\n\nA) The UAV hovers at the same location throughout to minimize mobility power.\n\nB) The policy has a two-level structure - outer level selects target radius, inner level optimizes trajectory. \n\nC) The UAV travels along the circumference of the circular cell during waiting phases.\n\nD) The approach is compared against static relays and shows minimal gains.\n\nCorrect Answer: B\n\nExplanation: The paper proposes a two-scale adaptive trajectory design, where in the outer decision, the UAV selects a target end radius given its current radius to balance delay and power. In the inner decision, it optimizes the trajectory between start and end radii to minimize delay and energy. Option B summarizes this two-level policy structure accurately. Option A is incorrect as the UAV is mobile. Option C is incorrect as the UAV circles at an optimal radius rather than along the cell circumference. Option D is contradicted by the over 50% delay reduction compared to static relays."}, "4": {"documentation": {"title": "Deep Supervised Discrete Hashing", "source": "Qi Li, Zhenan Sun, Ran He, Tieniu Tan", "docs_id": "1705.10999", "section": ["cs.CV"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Deep Supervised Discrete Hashing. With the rapid growth of image and video data on the web, hashing has been extensively studied for image or video search in recent years. Benefit from recent advances in deep learning, deep hashing methods have achieved promising results for image retrieval. However, there are some limitations of previous deep hashing methods (e.g., the semantic information is not fully exploited). In this paper, we develop a deep supervised discrete hashing algorithm based on the assumption that the learned binary codes should be ideal for classification. Both the pairwise label information and the classification information are used to learn the hash codes within one stream framework. We constrain the outputs of the last layer to be binary codes directly, which is rarely investigated in deep hashing algorithm. Because of the discrete nature of hash codes, an alternating minimization method is used to optimize the objective function. Experimental results have shown that our method outperforms current state-of-the-art methods on benchmark datasets."}, "answer": " Here is a 4-option multiple choice question with explanations for the given text:\n\nQuestion: Which of the following statements is true about the deep supervised discrete hashing algorithm described in the text?\n\nA) It uses only the pairwise label information to learn the hash codes.\n\nB) It constrains the outputs of an intermediate layer to be binary codes. \n\nC) It utilizes both pairwise and classification label information to learn hash codes.\n\nD) It optimizes the objective function using stochastic gradient descent.\n\nCorrect Answer: C\n\nExplanations:\n\nA) Incorrect. The text states that both pairwise label information and classification information are used to learn the hash codes. \n\nB) Incorrect. The text states that the outputs of the last layer are constrained to be binary codes, not an intermediate layer.\n\nC) Correct. The text mentions that both pairwise label information and classification information are exploited to learn the binary hash codes.\n\nD) Incorrect. The text states that an alternating minimization method is used to optimize the objective function, not stochastic gradient descent."}, "5": {"documentation": {"title": "End to End Video Segmentation for Driving : Lane Detection For\n  Autonomous Car", "source": "Wenhui Zhang, Tejas Mahale", "docs_id": "1812.05914", "section": ["cs.CV"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "End to End Video Segmentation for Driving : Lane Detection For\n  Autonomous Car. Safety and decline of road traffic accidents remain important issues of autonomous driving. Statistics show that unintended lane departure is a leading cause of worldwide motor vehicle collisions, making lane detection the most promising and challenge task for self-driving. Today, numerous groups are combining deep learning techniques with computer vision problems to solve self-driving problems. In this paper, a Global Convolution Networks (GCN) model is used to address both classification and localization issues for semantic segmentation of lane. We are using color-based segmentation is presented and the usability of the model is evaluated. A residual-based boundary refinement and Adam optimization is also used to achieve state-of-art performance. As normal cars could not afford GPUs on the car, and training session for a particular road could be shared by several cars. We propose a framework to get it work in real world. We build a real time video transfer system to get video from the car, get the model trained in edge server (which is equipped with GPUs), and send the trained model back to the car."}, "answer": " Question: What deep learning technique is used in the paper to address classification and localization issues for semantic segmentation of lanes?\n\nA) Convolutional Neural Networks\nB) Recurrent Neural Networks \nC) Global Convolution Networks\nD) Generative Adversarial Networks\n\nCorrect Answer: C) Global Convolution Networks\n\nExplanation: The paper uses a Global Convolution Networks (GCN) model to address both classification and localization issues for semantic segmentation of lanes. GCNs allow information to be propagated globally and enable precise pixel-level localization."}, "6": {"documentation": {"title": "A Family of Simplified Geometric Distortion Models for Camera\n  Calibration", "source": "Lili Ma, YangQuan Chen, and Kevin L. Moore", "docs_id": "cs/0308003", "section": ["cs.CV"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "A Family of Simplified Geometric Distortion Models for Camera\n  Calibration. The commonly used radial distortion model for camera calibration is in fact an assumption or a restriction. In practice, camera distortion could happen in a general geometrical manner that is not limited to the radial sense. This paper proposes a simplified geometrical distortion modeling method by using two different radial distortion functions in the two image axes. A family of simplified geometric distortion models is proposed, which are either simple polynomials or the rational functions of polynomials. Analytical geometric undistortion is possible using two of the distortion functions discussed in this paper and their performance can be improved by applying a piecewise fitting idea. Our experimental results show that the geometrical distortion models always perform better than their radial distortion counterparts. Furthermore, the proposed geometric modeling method is more appropriate for cameras whose distortion is not perfectly radially symmetric around the center of distortion."}, "answer": " Here is a 4-option multiple choice question on the paper:\n\nQuestion: Which of the following statements about the proposed geometric distortion models is true according to the paper?\n\nA) The geometric distortion models always perform worse than radial distortion models.\n\nB) The geometric distortion models can only use simple polynomial functions, not rational functions.\n\nC) The geometric distortion models allow modeling distortion that is not radially symmetric.\n\nD) Analytical geometric undistortion is not possible with the proposed geometric distortion models.\n\nCorrect Answer: C) The geometric distortion models allow modeling distortion that is not radially symmetric.\n\nExplanation: \nThe paper proposes simplified geometric distortion models that use two different radial distortion functions, allowing the modeling of distortion that is not limited to being radially symmetric around the center. The paper states that \"the geometrical distortion models always perform better than their radial distortion counterparts\", so A is incorrect. The paper discusses using both polynomials and rational functions, so B is incorrect. Analytical undistortion is possible with two of the proposed functions, so D is incorrect."}, "7": {"documentation": {"title": "3D Reconstruction from public webcams", "source": "Tianyu Wu, Konrad Schindler and Cenek Albl", "docs_id": "2108.09476", "section": ["cs.CV"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "3D Reconstruction from public webcams. We investigate the possibility of 3D scene reconstruction from two or more overlapping webcam streams. A large, and growing, number of webcams observe places of interest and are publicly accessible. The question naturally arises: can we make use of this free data source for 3D computer vision? It turns out that the task to reconstruct scene structure from webcam streams is very different from standard structure-from-motion (SfM), and conventional SfM pipelines fail. In the webcam setting there are very few views of the same scene, in most cases only the minimum of two. These viewpoints often have large baselines and/or scale differences, their overlap is rather limited, and besides unknown internal and external calibration also their temporal synchronisation is unknown. On the other hand, they record rather large fields of view continuously over long time spans, so that they regularly observe dynamic objects moving through the scene. We show how to leverage recent advances in several areas of computer vision to adapt SfM reconstruction to this particular scenario and reconstruct the unknown camera poses, the 3D scene structure, and the 3D trajectories of dynamic objects."}, "answer": " Here is a multi-form question on the 3D reconstruction from public webcams paper:\n\nQuestion: Which of the following statements about 3D reconstruction from webcam streams is true according to the paper?\n\nA) Conventional structure-from-motion pipelines work well for webcam reconstruction.\n\nB) Webcam streams have large baselines and scale differences between viewpoints. \n\nC) Webcams observe static scenes without any moving objects.\n\nD) The internal and external calibration of webcams is known in advance.\n\nCorrect Answer: B\n\nExplanation: The paper states that \"the task to reconstruct scene structure from webcam streams is very different from standard structure-from-motion (SfM), and conventional SfM pipelines fail.\" It also mentions that webcam viewpoints \"often have large baselines and/or scale differences.\" Therefore, option B is the correct answer. Options A, C, and D are incorrect based on statements from the paper."}, "8": {"documentation": {"title": "Secrecy and Energy Efficiency in Massive MIMO Aided Heterogeneous C-RAN:\n  A New Look at Interference", "source": "Lifeng Wang, Kai-Kit Wong, Maged Elkashlan, Arumugam Nallanathan, and\n  Sangarapillai Lambotharan", "docs_id": "1607.03344", "section": ["cs.NI", "cs.IT", "math.IT"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Secrecy and Energy Efficiency in Massive MIMO Aided Heterogeneous C-RAN:\n  A New Look at Interference. In this paper, we investigate the potential benefits of the massive multiple-input multiple-output (MIMO) enabled heterogeneous cloud radio access network (C-RAN) in terms of the secrecy and energy efficiency (EE). In this network, both remote radio heads (RRHs) and massive MIMO macrocell base stations (BSs) are deployed and soft fractional frequency reuse (S-FFR) is adopted to mitigate the inter-tier interference. We first examine the physical layer security by deriving the area ergodic secrecy rate and secrecy outage probability. Our results reveal that the use of massive MIMO and C-RAN can greatly improve the secrecy performance. For C-RAN, a large number of RRHs achieves high area ergodic secrecy rate and low secrecy outage probability, due to its powerful interference management. We find that for massive MIMO aided macrocells, having more antennas and serving more users improves secrecy performance. Then we derive the EE of the heterogeneous C-RAN, illustrating that increasing the number of RRHs significantly enhances the network EE. Furthermore, it is indicated that allocating more radio resources to the RRHs can linearly increase the EE of RRH tier and improve the network EE without affecting the EE of the macrocells."}, "answer": " Here is a 4-option multiple choice question on the paper:\n\nQuestion: Which of the following statements is true about the effects of massive MIMO on the secrecy performance of macrocells according to the paper?\n\nA) Having more antennas and serving more users degrades the secrecy performance of macrocells.\n\nB) Increasing the number of antennas does not affect the secrecy performance of macrocells. \n\nC) Having more antennas improves the secrecy performance but serving more users degrades it.\n\nD) Both having more antennas and serving more users improves the secrecy performance of macrocells.\n\nCorrect Answer: D\n\nExplanation: The paper states that \"for massive MIMO aided macrocells, having more antennas and serving more users improves secrecy performance.\" Therefore, option D is correct. Options A and C are incorrect interpretations. Option B contradicts what the paper states."}, "9": {"documentation": {"title": "Convolutional Generative Adversarial Networks with Binary Neurons for\n  Polyphonic Music Generation", "source": "Hao-Wen Dong and Yi-Hsuan Yang", "docs_id": "1804.09399", "section": ["cs.LG", "cs.AI", "cs.SD", "eess.AS", "stat.ML"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Convolutional Generative Adversarial Networks with Binary Neurons for\n  Polyphonic Music Generation. It has been shown recently that deep convolutional generative adversarial networks (GANs) can learn to generate music in the form of piano-rolls, which represent music by binary-valued time-pitch matrices. However, existing models can only generate real-valued piano-rolls and require further post-processing, such as hard thresholding (HT) or Bernoulli sampling (BS), to obtain the final binary-valued results. In this paper, we study whether we can have a convolutional GAN model that directly creates binary-valued piano-rolls by using binary neurons. Specifically, we propose to append to the generator an additional refiner network, which uses binary neurons at the output layer. The whole network is trained in two stages. Firstly, the generator and the discriminator are pretrained. Then, the refiner network is trained along with the discriminator to learn to binarize the real-valued piano-rolls the pretrained generator creates. Experimental results show that using binary neurons instead of HT or BS indeed leads to better results in a number of objective measures. Moreover, deterministic binary neurons perform better than stochastic ones in both objective measures and a subjective test. The source code, training data and audio examples of the generated results can be found at https://salu133445.github.io/bmusegan/ ."}, "answer": " Here is a multi-form question on the given text:\n\nQuestion: Which of the following statements is true about the convolutional GAN model proposed in the paper?\n\nA) It uses real-valued neurons in the output layer to directly generate binary piano-rolls.\n\nB) It requires post-processing like hard thresholding or Bernoulli sampling to binarize the real-valued piano-rolls. \n\nC) It has a refiner network with binary neurons appended to the generator to binarize the piano-rolls.\n\nD) It trains the refiner network along with the generator from scratch in one stage.\n\nCorrect Answer: C\n\nExplanation: The paper proposes a convolutional GAN model that appends an additional refiner network with binary neurons to the generator to directly generate binary piano-rolls. It does not use real-valued output neurons or require separate post-processing. The refiner network is trained in the second stage along with the discriminator after pretraining the generator."}, "10": {"documentation": {"title": "Non interactive simulation of correlated distributions is decidable", "source": "Anindya De and Elchanan Mossel and Joe Neeman", "docs_id": "1701.01485", "section": ["cs.CC", "cs.IT", "math.IT", "math.PR"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Non interactive simulation of correlated distributions is decidable. A basic problem in information theory is the following: Let $\\mathbf{P} = (\\mathbf{X}, \\mathbf{Y})$ be an arbitrary distribution where the marginals $\\mathbf{X}$ and $\\mathbf{Y}$ are (potentially) correlated. Let Alice and Bob be two players where Alice gets samples $\\{x_i\\}_{i \\ge 1}$ and Bob gets samples $\\{y_i\\}_{i \\ge 1}$ and for all $i$, $(x_i, y_i) \\sim \\mathbf{P}$. What joint distributions $\\mathbf{Q}$ can be simulated by Alice and Bob without any interaction? Classical works in information theory by G{\\'a}cs-K{\\\"o}rner and Wyner answer this question when at least one of $\\mathbf{P}$ or $\\mathbf{Q}$ is the distribution on $\\{0,1\\} \\times \\{0,1\\}$ where each marginal is unbiased and identical. However, other than this special case, the answer to this question is understood in very few cases. Recently, Ghazi, Kamath and Sudan showed that this problem is decidable for $\\mathbf{Q}$ supported on $\\{0,1\\} \\times \\{0,1\\}$. We extend their result to $\\mathbf{Q}$ supported on any finite alphabet. We rely on recent results in Gaussian geometry (by the authors) as well as a new \\emph{smoothing argument} inspired by the method of \\emph{boosting} from learning theory and potential function arguments from complexity theory and additive combinatorics."}, "answer": " Here is a multi-form question based on the given text:\n\nQuestion: According to the text, what is the main contribution of the recent work by Ghazi, Kamath and Sudan regarding the simulation of correlated distributions?\n\nA) They showed that the problem is decidable for distributions over {0,1} x {0,1}.\n\nB) They gave an efficient algorithm to simulate any correlated distribution. \n\nC) They proved that correlated distributions can always be simulated without interaction.\n\nD) They extended previous results to distributions over arbitrary finite alphabets.\n\nCorrect Answer: D\n\nExplanation: The text states that \"Recently, Ghazi, Kamath and Sudan showed that this problem is decidable for Q supported on {0,1} x {0,1}. We extend their result to Q supported on any finite alphabet.\" Therefore, the main contribution is extending previous decidability results from binary distributions to distributions over arbitrary finite alphabets."}, "11": {"documentation": {"title": "Tracking Triadic Cardinality Distributions for Burst Detection in Social\n  Activity Streams", "source": "Junzhou Zhao, John C.S. Lui, Don Towsley, Pinghui Wang, Xiaohong Guan", "docs_id": "1411.3808", "section": ["cs.SI", "physics.soc-ph"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Tracking Triadic Cardinality Distributions for Burst Detection in Social\n  Activity Streams. In everyday life, we often observe unusually frequent interactions among people before or during important events, e.g., we receive/send more greetings from/to our friends on Christmas Day, than usual. We also observe that some videos suddenly go viral through people's sharing in online social networks (OSNs). Do these seemingly different phenomena share a common structure? All these phenomena are associated with sudden surges of user activities in networks, which we call \"bursts\" in this work. We find that the emergence of a burst is accompanied with the formation of triangles in networks. This finding motivates us to propose a new method to detect bursts in OSNs. We first introduce a new measure, \"triadic cardinality distribution\", corresponding to the fractions of nodes with different numbers of triangles, i.e., triadic cardinalities, within a network. We demonstrate that this distribution changes when a burst occurs, and is naturally immunized against spamming social-bot attacks. Hence, by tracking triadic cardinality distributions, we can reliably detect bursts in OSNs. To avoid handling massive activity data generated by OSN users, we design an efficient sample-estimate solution to estimate the triadic cardinality distribution from sampled data. Extensive experiments conducted on real data demonstrate the usefulness of this triadic cardinality distribution and the effectiveness of our sample-estimate solution."}, "answer": " Here is a multi-form question on the document:\n\nQuestion: Which of the following statements is true about the triadic cardinality distribution according to the document?\n\nA) It corresponds to the fractions of nodes with different numbers of triangles within a network. \n\nB) It does not change when a burst occurs in a network.\n\nC) It is susceptible to spamming social-bot attacks.\n\nD) It can be estimated without handling massive activity data from users.\n\nCorrect Answer: A\n\nExplanation: The document states that the triadic cardinality distribution corresponds to the fractions of nodes with different numbers of triangles within a network. It also states that this distribution changes when a burst occurs, is immunized against social-bot attacks, and can be estimated from sampled data without handling massive user activity data."}, "12": {"documentation": {"title": "Cascaded Structure Tensor Framework for Robust Identification of Heavily\n  Occluded Baggage Items from Multi-Vendor X-ray Scans", "source": "Taimur Hassan, Salman H. Khan, Samet Akcay, Mohammed Bennamoun,\n  Naoufel Werghi", "docs_id": "1912.04251", "section": ["cs.CV", "cs.LG"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Cascaded Structure Tensor Framework for Robust Identification of Heavily\n  Occluded Baggage Items from Multi-Vendor X-ray Scans. In the last two decades, luggage scanning has globally become one of the prime aviation security concerns. Manual screening of the baggage items is a cumbersome, subjective and inefficient process. Hence, many researchers have developed Xray imagery-based autonomous systems to address these shortcomings. However, to the best of our knowledge, there is no framework, up to now, that can recognize heavily occluded and cluttered baggage items from multi-vendor X-ray scans. This paper presents a cascaded structure tensor framework which can automatically extract and recognize suspicious items irrespective of their position and orientation in the multi-vendor X-ray scans. The proposed framework is unique, as it intelligently extracts each object by iteratively picking contour based transitional information from different orientations and uses only a single feedforward convolutional neural network for the recognition. The proposed framework has been rigorously tested on publicly available GDXray and SIXray datasets containing a total of 1,067,381 X-ray scans where it significantly outperformed the state-of-the-art solutions by achieving the mean average precision score of 0.9343 and 0.9595 for extracting and recognizing suspicious items from GDXray and SIXray scans, respectively. Furthermore, the proposed framework has achieved 15.78% better time"}, "answer": " Here is a 4-option multiple choice question on the document:\n\nQuestion: Which of the following statements is true about the proposed cascaded structure tensor framework according to the document?\n\nA) It uses multiple convolutional neural networks for object recognition.\n\nB) It struggles to recognize heavily occluded and cluttered baggage items. \n\nC) It iteratively extracts object contours from different orientations using transitional information.\n\nD) It has been tested on private datasets and performs worse than existing methods.\n\nCorrect Answer: C\n\nExplanation: The document states that the proposed framework \"intelligently extracts each object by iteratively picking contour based transitional information from different orientations and uses only a single feedforward convolutional neural network for the recognition.\" Therefore, option C, which states that it extracts contours iteratively using transitional information, is correct. Options A, B, and D contradict information provided in the document."}, "13": {"documentation": {"title": "A Theory of Usable Information Under Computational Constraints", "source": "Yilun Xu, Shengjia Zhao, Jiaming Song, Russell Stewart, Stefano Ermon", "docs_id": "2002.10689", "section": ["cs.LG", "stat.ML"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "A Theory of Usable Information Under Computational Constraints. We propose a new framework for reasoning about information in complex systems. Our foundation is based on a variational extension of Shannon's information theory that takes into account the modeling power and computational constraints of the observer. The resulting \\emph{predictive $\\mathcal{V}$-information} encompasses mutual information and other notions of informativeness such as the coefficient of determination. Unlike Shannon's mutual information and in violation of the data processing inequality, $\\mathcal{V}$-information can be created through computation. This is consistent with deep neural networks extracting hierarchies of progressively more informative features in representation learning. Additionally, we show that by incorporating computational constraints, $\\mathcal{V}$-information can be reliably estimated from data even in high dimensions with PAC-style guarantees. Empirically, we demonstrate predictive $\\mathcal{V}$-information is more effective than mutual information for structure learning and fair representation learning."}, "answer": " Here is a multi-form question based on the given documentation:\n\nQuestion: Which of the following statements about predictive $\\mathcal{V}$-information is true according to the documentation?\n\nA) It is equivalent to Shannon's mutual information and always satisfies the data processing inequality. \n\nB) It can be reliably estimated from high-dimensional data with PAC-style guarantees by incorporating computational constraints.\n\nC) It is less effective than mutual information for structure learning and fair representation learning.\n\nD) It encompasses mutual information but always satisfies the data processing inequality like Shannon's mutual information.\n\nCorrect Answer: B\n\nExplanation: According to the documentation, predictive $\\mathcal{V}$-information differs from Shannon's mutual information in that it can violate the data processing inequality, as it can be created through computation. Additionally, the documentation states that by incorporating computational constraints, predictive $\\mathcal{V}$-information can be reliably estimated from high-dimensional data with PAC-style guarantees. The documentation also notes empirical results showing predictive $\\mathcal{V}$-information is more effective than mutual information for structure learning and fair representation learning."}, "14": {"documentation": {"title": "Wireless Communication via Double IRS: Channel Estimation and Passive\n  Beamforming Designs", "source": "Changsheng You, Beixiong Zheng, and Rui Zhang", "docs_id": "2008.11439", "section": ["cs.IT", "cs.NI", "math.IT"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Wireless Communication via Double IRS: Channel Estimation and Passive\n  Beamforming Designs. In this letter, we study efficient channel estimation and passive beamforming designs for a double-intelligent reflecting surface (IRS) aided single-user communication system, where a user communicates with an access point (AP) via the cascaded user-IRS 1-IRS 2-AP double-reflection link. First, a general channel estimation scheme is proposed for the system under any arbitrary inter-IRS channel, where all coefficients of the cascaded channel are estimated. Next, for the typical scenario with a line-of-sight (LoS)-dominant inter-IRS channel, we propose another customized scheme to estimate two signature vectors of the rank-one cascaded channel with significantly less channel training time than the first scheme. For the two proposed channel estimation schemes, we further optimize their corresponding cooperative passive beamforming for data transmission to maximize the achievable rate with the training overhead and channel estimation error taken into account. Numerical results show that deploying two cooperative IRSs with the proposed channel estimation and passive beamforming designs achieves significant rate enhancement as compared to the conventional case of single IRS deployment."}, "answer": " Question: What is the main contribution of the paper \"Wireless Communication via Double IRS: Channel Estimation and Passive Beamforming Designs\"?\n\nA) Proposing a new modulation scheme for IRS-assisted wireless communication\n\nB) Studying channel estimation and passive beamforming for a system with two cooperative IRSs \n\nC) Analyzing the capacity limits of IRS-assisted multi-user MIMO systems\n\nD) Designing optimal active beamforming techniques for IRS-aided networks\n\nCorrect Answer: B\n\nExplanations:\n\nThe paper studies channel estimation and passive beamforming designs for a system with two cooperative IRSs assisting the communication between a single user and an access point. It proposes channel estimation schemes for this double IRS system and optimizes the passive beamforming based on the estimated channels. Hence, the main contribution is studying channel estimation and passive beamforming for the double IRS system, not proposing a new modulation scheme, analyzing capacity limits or active beamforming as stated in options A, C and D respectively."}, "15": {"documentation": {"title": "Convolutional RNN: an Enhanced Model for Extracting Features from\n  Sequential Data", "source": "Gil Keren and Bj\\\"orn Schuller", "docs_id": "1602.05875", "section": ["stat.ML", "cs.CL"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Convolutional RNN: an Enhanced Model for Extracting Features from\n  Sequential Data. Traditional convolutional layers extract features from patches of data by applying a non-linearity on an affine function of the input. We propose a model that enhances this feature extraction process for the case of sequential data, by feeding patches of the data into a recurrent neural network and using the outputs or hidden states of the recurrent units to compute the extracted features. By doing so, we exploit the fact that a window containing a few frames of the sequential data is a sequence itself and this additional structure might encapsulate valuable information. In addition, we allow for more steps of computation in the feature extraction process, which is potentially beneficial as an affine function followed by a non-linearity can result in too simple features. Using our convolutional recurrent layers we obtain an improvement in performance in two audio classification tasks, compared to traditional convolutional layers. Tensorflow code for the convolutional recurrent layers is publicly available in https://github.com/cruvadom/Convolutional-RNN."}, "answer": " Question: What type of neural network does the paper propose to enhance feature extraction from sequential data compared to traditional convolutional layers?\n\nA) A convolutional neural network with recurrent layers instead of convolutional layers\nB) A recurrent neural network with convolutional layers instead of recurrent layers  \nC) A convolutional recurrent neural network that feeds patches of data into a recurrent neural network before feature extraction\nD) A recurrent convolutional neural network that feeds hidden states into convolutional layers before feature extraction\n\nCorrect Answer: C) A convolutional recurrent neural network that feeds patches of data into a recurrent neural network before feature extraction\n\nExplanations:\nThe paper proposes a convolutional recurrent neural network that feeds patches of sequential data into a recurrent neural network and uses the outputs or hidden states of the recurrent units to compute the extracted features. This enhances feature extraction compared to traditional convolutional layers by exploiting the sequential structure in patches of data."}, "16": {"documentation": {"title": "Learning Music Helps You Read: Using Transfer to Study Linguistic\n  Structure in Language Models", "source": "Isabel Papadimitriou and Dan Jurafsky", "docs_id": "2004.14601", "section": ["cs.CL"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Learning Music Helps You Read: Using Transfer to Study Linguistic\n  Structure in Language Models. We propose transfer learning as a method for analyzing the encoding of grammatical structure in neural language models. We train LSTMs on non-linguistic data and evaluate their performance on natural language to assess which kinds of data induce generalizable structural features that LSTMs can use for natural language. We find that training on non-linguistic data with latent structure (MIDI music or Java code) improves test performance on natural language, despite no overlap in surface form or vocabulary. To pinpoint the kinds of abstract structure that models may be encoding to lead to this improvement, we run similar experiments with two artificial parentheses languages: one which has a hierarchical recursive structure, and a control which has paired tokens but no recursion. Surprisingly, training a model on either of these artificial languages leads to the same substantial gains when testing on natural language. Further experiments on transfer between natural languages controlling for vocabulary overlap show that zero-shot performance on a test language is highly correlated with typological syntactic similarity to the training language, suggesting that representations induced by pre-training correspond to the cross-linguistic syntactic properties. Our results provide insights into the ways that neural models represent abstract syntactic structure, and also about the kind of structural inductive biases which allow for natural language acquisition."}, "answer": " Here is a 4-option multiple choice question on the given research summary:\n\nQuestion: According to the research summary, which of the following statements is true about the effect of training LSTMs on non-linguistic data with latent structure?\n\nA) Training on MIDI music or Java code harms test performance on natural language.\n\nB) Training on MIDI music or Java code does not affect test performance on natural language. \n\nC) Training on MIDI music or Java code improves test performance on natural language despite no overlap in surface form or vocabulary.\n\nD) Training on MIDI music or Java code leads to worse syntactic representations for natural language.\n\nCorrect Answer: C\n\nExplanation: The research found that training LSTMs on non-linguistic data with latent structure like MIDI music or Java code improves test performance on natural language, even though there is no overlap in surface form or vocabulary between the training data and natural language test data."}, "17": {"documentation": {"title": "Decidability Results for Multi-objective Stochastic Games", "source": "Romain Brenguier and Vojt\\v{e}ch Forejt", "docs_id": "1605.03811", "section": ["cs.GT", "cs.LO"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Decidability Results for Multi-objective Stochastic Games. We study stochastic two-player turn-based games in which the objective of one player is to ensure several infinite-horizon total reward objectives, while the other player attempts to spoil at least one of the objectives. The games have previously been shown not to be determined, and an approximation algorithm for computing a Pareto curve has been given. The major drawback of the existing algorithm is that it needs to compute Pareto curves for finite horizon objectives (for increasing length of the horizon), and the size of these Pareto curves can grow unboundedly, even when the infinite-horizon Pareto curve is small. By adapting existing results, we first give an algorithm that computes the Pareto curve for determined games. Then, as the main result of the paper, we show that for the natural class of stopping games and when there are two reward objectives, the problem of deciding whether a player can ensure satisfaction of the objectives with given thresholds is decidable. The result relies on intricate and novel proof which shows that the Pareto curves contain only finitely many points. As a consequence, we get that the two-objective discounted-reward problem for unrestricted class of stochastic games is decidable."}, "answer": " Here is a 4-option multiple choice question on the paper:\n\nQuestion: Which of the following statements is true about the results presented in the paper on multi-objective stochastic games?\n\nA) The paper shows that Pareto curves for infinite-horizon objectives can be computed by approximating using finite horizons of increasing length.\n\nB) The paper gives an algorithm to compute Pareto curves for arbitrary stochastic games with multiple objectives. \n\nC) For stopping games with two objectives, the paper shows decidability of threshold problems by proving Pareto curves are finite.\n\nD) The paper proves that all multi-objective stochastic games are determined.\n\nCorrect Answer: C\n\nExplanation: \nThe paper studies decidability of threshold problems for two-objective stopping games by showing the Pareto curves contain only finitely many points. It does not prove decidability for general multi-objective stochastic games. The approximation algorithm described computes finite horizon Pareto curves whose size can grow unboundedly. The games are not shown to be determined."}, "18": {"documentation": {"title": "Measures of path-based nonlinear expansion rates and Lagrangian\n  uncertainty in stochastic flows", "source": "Michal Branicki and Kenneth Uda", "docs_id": "1810.07567", "section": ["math.DS", "cs.IT", "math.IT", "math.PR"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Measures of path-based nonlinear expansion rates and Lagrangian\n  uncertainty in stochastic flows. We develop a probabilistic characterisation of trajectorial expansion rates in non-autonomous stochastic dynamical systems that can be defined over a finite time interval and used for the subsequent uncertainty quantification in Lagrangian (trajectory-based) predictions. These expansion rates are quantified via certain divergences (pre-metrics) between probability measures induced by the laws of the stochastic flow associated with the underlying dynamics. We construct scalar fields of finite-time divergence/expansion rates, show their existence and space-time continuity for general stochastic flows. Combining these divergence rate fields with our 'information inequalities' derived in allows for quantification and mitigation of the uncertainty in path-based observables estimated from simplified models in a way that is amenable to algorithmic implementations, and it can be utilised in information-geometric analysis of statistical estimation and inference, as well as in a data-driven machine/deep learning of coarse-grained models. We also derive a link between the divergence rates and finite-time Lyapunov exponents for probability measures and for path-based observables."}, "answer": " Here is a multi-form question on the given documentation:\n\nQuestion: Which of the following statements is true about the expansion rates developed in the paper?\n\nA) The expansion rates do not allow for uncertainty quantification in Lagrangian predictions.\n\nB) The expansion rates are quantified using divergences between probability measures induced by the stochastic flow. \n\nC) The expansion rates cannot be used in data-driven machine/deep learning of coarse-grained models.\n\nD) The expansion rates have no link to finite-time Lyapunov exponents.\n\nCorrect Answer: B\n\nExplanation: According to the documentation, the expansion rates are quantified via divergences between probability measures induced by the laws of the stochastic flow. So B is the correct option. A is incorrect as the rates allow uncertainty quantification in Lagrangian predictions. C is incorrect as the rates can be used in machine/deep learning. D is incorrect because the paper derives a link between the rates and finite-time Lyapunov exponents."}, "19": {"documentation": {"title": "Dynamic Interaction of Transportation and Power Distribution Networks\n  With Electric Vehicles", "source": "Li Jiaqi, Xu Xiaoyuan, Yan Zheng, Wang Han, Chen Yue", "docs_id": "2112.04683", "section": ["eess.SY", "cs.SY"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Dynamic Interaction of Transportation and Power Distribution Networks\n  With Electric Vehicles. The increasing global spread of electric vehicles has introduced significant interdependence between transportation and power networks. Most of the previous studies on the coupled networks are based on static models, and the spatial and temporal variations of traffic and power flows are neglected, which is not suitable for short-term operation. This paper constructs a dynamic interaction model of coupled networks. First, the dynamic traffic assignment (DTA) model is established considering departure time and route choices simultaneously, and a nested diagonalization method is exploited to solve it. Then, based on DTA and multi-period optimal power flow, the equilibrium state of coupled networks is designed as the solution of a fixed-point problem. Moreover, the solution existence is proved based on mild assumptions. Third, the linearization and convex relaxation techniques are used to improve computational efficiency. A Monte Carlo simulation technique is developed to evaluate the influence of uncertain travel demands on coupled networks. Numerical simulations of the interaction analyses of coupled networks in both deterministic and uncertain conditions are presented."}, "answer": " Here is a 4-option multiple choice question on the paper:\n\nQuestion: Which of the following statements is true about the dynamic interaction model of transportation and power distribution networks presented in the paper?\n\nA) It is based on static models and neglects spatial and temporal variations in traffic and power flows.\n\nB) It uses dynamic traffic assignment and multi-period optimal power flow to model the equilibrium state as a fixed-point problem. \n\nC) It only considers departure time choices and ignores route choices in the dynamic traffic assignment model.\n\nD) It uses linearization techniques but does not employ any convex relaxation to improve computational efficiency.\n\nCorrect Answer: B\n\nExplanation: According to the documentation, the paper constructs a dynamic interaction model using dynamic traffic assignment considering both departure times and route choices, along with multi-period optimal power flow to model the equilibrium state as a fixed-point problem. It uses linearization and convex relaxation techniques to improve computational efficiency. Option B summarizes this accurately, while the other options are incorrect based on the information given."}, "20": {"documentation": {"title": "TCDesc: Learning Topology Consistent Descriptors", "source": "Honghu Pan, Fanyang Meng, Zhenyu He, Yongsheng Liang, Wei Liu", "docs_id": "2006.03254", "section": ["cs.CV"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "TCDesc: Learning Topology Consistent Descriptors. Triplet loss is widely used for learning local descriptors from image patch. However, triplet loss only minimizes the Euclidean distance between matching descriptors and maximizes that between the non-matching descriptors, which neglects the topology similarity between two descriptor sets. In this paper, we propose topology measure besides Euclidean distance to learn topology consistent descriptors by considering kNN descriptors of positive sample. First we establish a novel topology vector for each descriptor followed by Locally Linear Embedding (LLE) to indicate the topological relation among the descriptor and its kNN descriptors. Then we define topology distance between descriptors as the difference of their topology vectors. Last we employ the dynamic weighting strategy to fuse Euclidean distance and topology distance of matching descriptors and take the fusion result as the positive sample distance in the triplet loss. Experimental results on several benchmarks show that our method performs better than state-of-the-arts results and effectively improves the performance of triplet loss."}, "answer": " Here is a 4-option multiple choice question on the paper:\n\nQuestion: Which of the following statements is true about the topology consistent descriptor learning method proposed in the paper?\n\nA) It uses Euclidean distance only to measure similarity between descriptors. \n\nB) It establishes a topology vector using PCA instead of LLE.\n\nC) It fuses Euclidean distance and topology distance using a static weighting scheme.\n\nD) It shows improved performance compared to using triplet loss alone on benchmarks.\n\nCorrect Answer: D) It shows improved performance compared to using triplet loss alone on benchmarks.\n\nExplanations:\n\nA) Incorrect. The method uses both Euclidean distance and a proposed topology distance measure. \n\nB) Incorrect. It uses LLE, not PCA, to establish the topology vector.\n\nC) Incorrect. It uses a dynamic, not static, weighting scheme to fuse the two distances.\n\nD) Correct. The results section shows improved performance over triplet loss baselines on several benchmarks."}, "21": {"documentation": {"title": "Keeping Your Eye on the Ball: Trajectory Attention in Video Transformers", "source": "Mandela Patrick, Dylan Campbell, Yuki M. Asano, Ishan Misra, Florian\n  Metze, Christoph Feichtenhofer, Andrea Vedaldi, Jo\\~ao F. Henriques", "docs_id": "2106.05392", "section": ["cs.CV"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Keeping Your Eye on the Ball: Trajectory Attention in Video Transformers. In video transformers, the time dimension is often treated in the same way as the two spatial dimensions. However, in a scene where objects or the camera may move, a physical point imaged at one location in frame $t$ may be entirely unrelated to what is found at that location in frame $t+k$. These temporal correspondences should be modeled to facilitate learning about dynamic scenes. To this end, we propose a new drop-in block for video transformers -- trajectory attention -- that aggregates information along implicitly determined motion paths. We additionally propose a new method to address the quadratic dependence of computation and memory on the input size, which is particularly important for high resolution or long videos. While these ideas are useful in a range of settings, we apply them to the specific task of video action recognition with a transformer model and obtain state-of-the-art results on the Kinetics, Something--Something V2, and Epic-Kitchens datasets. Code and models are available at: https://github.com/facebookresearch/Motionformer"}, "answer": " Here is a multi-form question on the paper:\n\nQuestion: Which of the following statements is true about the trajectory attention mechanism proposed in the paper Keeping Your Eye on the Ball: Trajectory Attention in Video Transformers?\n\nA) It treats the time dimension the same as the spatial dimensions in a video transformer model.\n\nB) It aggregates information along motion paths determined by optical flow. \n\nC) It reduces the quadratic growth of computation with input size using a sparse attention pattern.\n\nD) It outperforms prior methods on action recognition in the Kinetics and Epic-Kitchens datasets.\n\nCorrect Answer: B\n\nExplanation: \nThe paper proposes trajectory attention to aggregate information along implicit motion paths, as opposed to treating time the same as spatial dimensions (A). It uses trajectory attention to achieve state-of-the-art results on several action recognition datasets (D). The paper also proposes a method to reduce the quadratic growth of computation with input size (C)."}, "22": {"documentation": {"title": "3D Shape Synthesis for Conceptual Design and Optimization Using\n  Variational Autoencoders", "source": "Wentai Zhang, Zhangsihao Yang, Haoliang Jiang, Suyash Nigam, Soji\n  Yamakawa, Tomotake Furuhata, Kenji Shimada, Levent Burak Kara", "docs_id": "1904.07964", "section": ["cs.LG", "cs.CG", "cs.NE", "stat.ML"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "3D Shape Synthesis for Conceptual Design and Optimization Using\n  Variational Autoencoders. We propose a data-driven 3D shape design method that can learn a generative model from a corpus of existing designs, and use this model to produce a wide range of new designs. The approach learns an encoding of the samples in the training corpus using an unsupervised variational autoencoder-decoder architecture, without the need for an explicit parametric representation of the original designs. To facilitate the generation of smooth final surfaces, we develop a 3D shape representation based on a distance transformation of the original 3D data, rather than using the commonly utilized binary voxel representation. Once established, the generator maps the latent space representations to the high-dimensional distance transformation fields, which are then automatically surfaced to produce 3D representations amenable to physics simulations or other objective function evaluation modules. We demonstrate our approach for the computational design of gliders that are optimized to attain prescribed performance scores. Our results show that when combined with genetic optimization, the proposed approach can generate a rich set of candidate concept designs that achieve prescribed functional goals, even when the original dataset has only a few or no solutions that achieve these goals."}, "answer": " Here is a 4-option multiple choice question on the paper:\n\nQuestion: Which of the following statements is true about the 3D shape synthesis method proposed in the paper?\n\nA) It uses a binary voxel representation to generate smooth final surfaces.\n\nB) It learns an encoding of the training samples using a supervised learning approach. \n\nC) It can generate new designs optimized for prescribed functional goals even when the original dataset has no such solutions.\n\nD) It requires an explicit parametric representation of the original designs.\n\nCorrect Answer: C\n\nExplanation: The paper proposes an unsupervised variational autoencoder method to learn a generative model from a corpus of 3D designs. It uses a distance field representation, not binary voxels, to enable generating smooth surfaces. The method can generate optimized new designs even if none exist in the original dataset, as it explores the latent space. It does not require explicit parametric representations of the original designs."}, "23": {"documentation": {"title": "Study of Distributed Conjugate Gradient Strategies for Distributed\n  Estimation Over Sensor Networks", "source": "R. C. de Lamare", "docs_id": "1601.04102", "section": ["cs.DC", "cs.IT", "math.IT"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Study of Distributed Conjugate Gradient Strategies for Distributed\n  Estimation Over Sensor Networks. This paper presents distributed conjugate gradient algorithms for distributed parameter estimation and spectrum estimation over wireless sensor networks. In particular, distributed conventional conjugate gradient (CCG) and modified conjugate gradient (MCG) are considered, together with incremental and diffusion adaptive solutions. The distributed CCG and MCG algorithms have an improved performance in terms of mean square error as compared with least--mean square (LMS)--based algorithms and a performance that is close to recursive least--squares (RLS) algorithms. In comparison with existing centralized or distributed estimation strategies, key features of the proposed algorithms are: 1) more accurate estimates and faster convergence speed can be obtained; 2) the design of preconditioners for CG algorithms, which have the ability to improve the performance of the proposed CG algorithms is presented and 3) the proposed algorithms are implemented in the area of distributed parameter estimation and spectrum estimation. The performance of the proposed algorithms for distributed estimation is illustrated via simulations and the resulting algorithms are distributed, cooperative and able to respond in real time to change in the environment."}, "answer": " Question: Which of the following statements accurately summarizes a key contribution of the paper \"Study of Distributed Conjugate Gradient Strategies for Distributed Estimation Over Sensor Networks\"?\n\nA) The paper proposes distributed conjugate gradient algorithms for distributed parameter and spectrum estimation that have improved performance compared to LMS-based methods. The design of preconditioners for the CG algorithms is also presented.\n\nB) The paper shows that recursive least squares algorithms always outperform conjugate gradient methods for distributed estimation problems.\n\nC) The paper proves that conjugate gradient methods cannot be effectively distributed over wireless sensor networks.\n\nD) The paper introduces a new class of incremental and diffusion adaptive solutions that significantly outperform existing distributed estimation strategies.\n\nCorrect Answer: A"}, "24": {"documentation": {"title": "The $\\aleph$ Calculus", "source": "Hannah Earley", "docs_id": "2011.14989", "section": ["cs.PL"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "The $\\aleph$ Calculus. Motivated by a need for a model of reversible computation appropriate for a Brownian molecular architecture, the $\\aleph$ calculus is introduced. This novel model is declarative, concurrent, and term-based--encapsulating all information about the program data and state within a single structure in order to obviate the need for a von Neumann-style discrete computational 'machine', a challenge in a molecular environment. The name is inspired by the Greek for 'not forgotten', due to the emphasis on (reversibly) learning and un-learning knowledge of different variables. To demonstrate its utility for this purpose, as well as its elegance as a programming language, a number of examples are presented; two of these examples, addition/subtraction and squaring/square-rooting, are furnished with designs for abstract molecular implementations. A natural by-product of these examples and accompanying syntactic sugar is the design of a fully-fledged programming language, alethe, which is also presented along with an interpreter. Efficiently simulating $\\aleph$ on a deterministic computer necessitates some static analysis of programs within the alethe interpreter in order to render the declarative programs sequential. Finally, work towards a type system appropriate for such a reversible, declarative model of computation is presented."}, "answer": " Here is a multi-form question on the $\\aleph$ calculus:\n\nQuestion: Which of the following statements about the $\\aleph$ calculus is true?\n\nA) The $\\aleph$ calculus is imperative, distributed, and object-oriented.\n\nB) The $\\aleph$ calculus is procedural, concurrent, and stack-based. \n\nC) The $\\aleph$ calculus is declarative, concurrent, and term-based.\n\nD) The $\\aleph$ calculus is functional, sequential, and register-based.\n\nCorrect Answer: C\n\nExplanation: According to the documentation, the $\\aleph$ calculus is a novel model that is declarative, concurrent, and term-based. It encapsulates all program information within a single structure to avoid the need for a von Neumann machine, which is a challenge in a molecular environment. Therefore, option C is the correct statement.\n\nOptions A, B, and D describe models of computation with characteristics that contradict the documentation. The $\\aleph$ calculus is not imperative, procedural, distributed, object-oriented, stack-based, functional, or register-based. It is specifically designed to be declarative, concurrent, and term-based."}, "25": {"documentation": {"title": "Cross-Cultural and Cultural-Specific Production and Perception of Facial\n  Expressions of Emotion in the Wild", "source": "Ramprakash Srinivasan, Aleix M. Martinez", "docs_id": "1808.04399", "section": ["cs.CV"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Cross-Cultural and Cultural-Specific Production and Perception of Facial\n  Expressions of Emotion in the Wild. Automatic recognition of emotion from facial expressions is an intense area of research, with a potentially long list of important application. Yet, the study of emotion requires knowing which facial expressions are used within and across cultures in the wild, not in controlled lab conditions; but such studies do not exist. Which and how many cross-cultural and cultural-specific facial expressions do people commonly use? And, what affect variables does each expression communicate to observers? If we are to design technology that understands the emotion of users, we need answers to these two fundamental questions. In this paper, we present the first large-scale study of the production and visual perception of facial expressions of emotion in the wild. We find that of the 16,384 possible facial configurations that people can theoretically produce, only 35 are successfully used to transmit emotive information across cultures, and only 8 within a smaller number of cultures. Crucially, we find that visual analysis of cross-cultural expressions yields consistent perception of emotion categories and valence, but not arousal. In contrast, visual analysis of cultural-specific expressions yields consistent perception of valence and arousal, but not of emotion categories. Additionally, we find that the number of expressions used to communicate each emotion is also different, e.g., 17 expressions transmit happiness, but only 1 is used to convey disgust."}, "answer": " Here is a 4-option multiple choice question on the paper:\n\nQuestion: According to the paper, how many facial expressions are successfully used to transmit emotive information across cultures?\n\nA) 8 \nB) 16,384\nC) 35\nD) 17\n\nCorrect Answer: C\n\nExplanation: The paper states that \"of the 16,384 possible facial configurations that people can theoretically produce, only 35 are successfully used to transmit emotive information across cultures\". So the correct number is 35."}, "26": {"documentation": {"title": "Pretext Tasks selection for multitask self-supervised speech\n  representation learning", "source": "Salah Zaiem, Titouan Parcollet and Slim Essid", "docs_id": "2107.00594", "section": ["eess.AS", "cs.LG", "cs.SD", "stat.ML"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Pretext Tasks selection for multitask self-supervised speech\n  representation learning. Through solving pretext tasks, self-supervised learning leverages unlabeled data to extract useful latent representations replacing traditional input features in the downstream task. In audio/speech signal processing, a wide range of features where engineered through decades of research efforts. As it turns out, learning to predict such features (a.k.a pseudo-labels) has proven to be a particularly relevant pretext task, leading to useful self-supervised representations which prove to be effective for downstream tasks. However, methods and common practices for combining such pretext tasks for better performance on the downstream task have not been explored and understood properly. In fact, the process relies almost exclusively on a computationally heavy experimental procedure, which becomes intractable with the increase of the number of pretext tasks. This paper introduces a method to select a group of pretext tasks among a set of candidates. The method we propose estimates calibrated weights for the partial losses corresponding to the considered pretext tasks during the self-supervised training process. The experiments conducted on automatic speech recognition, speaker and emotion recognition validate our approach, as the groups selected and weighted with our method perform better than classic baselines, thus facilitating the selection and combination of relevant pseudo-labels for self-supervised representation learning."}, "answer": " Question: Which of the following statements best summarizes the key idea presented in the given text?\n\nA) Self-supervised learning can leverage unlabeled data to extract useful latent representations for downstream tasks, but combining pretext tasks relies on heavy experimentation. The proposed method estimates weights for pretext task losses to select better groups.\n\nB) Engineered audio features have been researched for decades but are now being replaced by self-supervised representations which are more effective. The process of combining pretext tasks is computationally expensive as the number increases.\n\nC) Pretext tasks like predicting engineered features can provide useful representations in self-supervised learning. But it's unclear how to best combine tasks for optimal downstream performance. The paper introduces a weighting method to select good pretext groups. \n\nD) Automatic speech recognition has seen great progress recently using self-supervised learning and pretext tasks. But more research is needed on how to pick the right tasks and combine them effectively. The proposed method doesn't fully solve this problem.\n\nCorrect Answer: C\n\nExplanation: Option C best summarizes the key points that self-supervised learning uses pretext tasks like predicting engineered features to get useful representations, but it's unclear how to best combine pretext tasks. The paper introduces a weighting method to select good groups of pretext tasks."}, "27": {"documentation": {"title": "Emergence and structure of decentralised trade networks around dark web\n  marketplaces", "source": "Matthieu Nadini, Alberto Bracci, Abeer ElBahrawy, Philip Gradwell,\n  Alexander Teytelboym, Andrea Baronchelli", "docs_id": "2111.01774", "section": ["physics.soc-ph", "cs.CY"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Emergence and structure of decentralised trade networks around dark web\n  marketplaces. Dark web marketplaces (DWMs) are online platforms that facilitate illicit trade among millions of users generating billions of dollars in annual revenue. Recently, two interview-based studies have suggested that DWMs may also promote the emergence of direct user-to-user (U2U) trading relationships. Here, we quantify the scale of, and thoroughly investigate, U2U trading around DWMs by analysing 31 million Bitcoin transactions among users of 40 DWMs between June 2011 and Jan 2021. We find that half of the DWM users trade through U2U pairs generating a total trading volume greater than DWMs themselves. We then show that hundreds of thousands of DWM users form stable trading pairs that are persistent over time. Users in stable pairs are typically the ones with the largest trading volume on DWMs. Then, we show that new U2U pairs often form while both users are active on the same DWM, suggesting the marketplace may serve as a catalyst for new direct trading relationships. Finally, we reveal that stable U2U pairs tend to survive DWM closures and that they were not affected by COVID-19, indicating that their trading activity is resilient to external shocks. Our work unveils sophisticated patterns of trade emerging in the dark web and highlights the importance of investigating user behaviour beyond the immediate buyer-seller network on a single marketplace."}, "answer": " Here is a multi-form question on the dark web marketplace research:\n\nQuestion: According to the research on dark web marketplaces, which of the following statements is true?\n\nA) The total trading volume of user-to-user pairs was less than the volume on dark web marketplaces themselves.\n\nB) There were only a few stable trading relationships formed between users over time. \n\nC) New user-to-user trading pairs tended to form when users were active on different dark web marketplaces.\n\nD) Stable user-to-user trading pairs were resilient and persisted despite dark web marketplace closures.\n\nCorrect Answer: D) Stable user-to-user trading pairs were resilient and persisted despite dark web marketplace closures.\n\nExplanation: The research found that stable user-to-user trading pairs, formed while users were active on the same dark web marketplace, tended to survive even when the marketplace itself was shut down. This indicates these trading relationships were resilient to external shocks."}, "28": {"documentation": {"title": "Data-Driven Characterization and Detection of COVID-19 Themed Malicious\n  Websites", "source": "Mir Mehedi Ahsan Pritom, Kristin M. Schweitzer, Raymond M. Bateman,\n  Min Xu, Shouhuai Xu", "docs_id": "2102.13226", "section": ["cs.CR"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Data-Driven Characterization and Detection of COVID-19 Themed Malicious\n  Websites. COVID-19 has hit hard on the global community, and organizations are working diligently to cope with the new norm of \"work from home\". However, the volume of remote work is unprecedented and creates opportunities for cyber attackers to penetrate home computers. Attackers have been leveraging websites with COVID-19 related names, dubbed COVID-19 themed malicious websites. These websites mostly contain false information, fake forms, fraudulent payments, scams, or malicious payloads to steal sensitive information or infect victims' computers. In this paper, we present a data-driven study on characterizing and detecting COVID-19 themed malicious websites. Our characterization study shows that attackers are agile and are deceptively crafty in designing geolocation targeted websites, often leveraging popular domain registrars and top-level domains. Our detection study shows that the Random Forest classifier can detect COVID-19 themed malicious websites based on the lexical and WHOIS features defined in this paper, achieving a 98% accuracy and 2.7% false-positive rate."}, "answer": " Here is a multi-form question based on the given text:\n\nQuestion: According to the paper, what technique did the researchers use to detect COVID-19 themed malicious websites?\n\nA) Logistic regression\nB) Support vector machines \nC) Random Forest classifier\nD) Neural networks\n\nCorrect Answer: C\n\nExplanations:\n\nA) Incorrect. The paper did not use logistic regression for detection.\n\nB) Incorrect. Support vector machines were not used for detection. \n\nC) Correct. The paper states \"Our detection study shows that the Random Forest classifier can detect COVID-19 themed malicious websites based on the lexical and WHOIS features defined in this paper, achieving a 98% accuracy and 2.7% false-positive rate.\"\n\nD) Incorrect. Neural networks were not used for detection."}, "29": {"documentation": {"title": "Dual Attention-in-Attention Model for Joint Rain Streak and Raindrop\n  Removal", "source": "Kaihao Zhang, Dongxu Li, Wenhan Luo, Wenqi Ren", "docs_id": "2103.07051", "section": ["cs.CV"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Dual Attention-in-Attention Model for Joint Rain Streak and Raindrop\n  Removal. Rain streaks and rain drops are two natural phenomena, which degrade image capture in different ways. Currently, most existing deep deraining networks take them as two distinct problems and individually address one, and thus cannot deal adequately with both simultaneously. To address this, we propose a Dual Attention-in-Attention Model (DAiAM) which includes two DAMs for removing both rain streaks and raindrops. Inside the DAM, there are two attentive maps - each of which attends to the heavy and light rainy regions, respectively, to guide the deraining process differently for applicable regions. In addition, to further refine the result, a Differential-driven Dual Attention-in-Attention Model (D-DAiAM) is proposed with a \"heavy-to-light\" scheme to remove rain via addressing the unsatisfying deraining regions. Extensive experiments on one public raindrop dataset, one public rain streak and our synthesized joint rain streak and raindrop (JRSRD) dataset have demonstrated that the proposed method not only is capable of removing rain streaks and raindrops simultaneously, but also achieves the state-of-the-art performance on both tasks."}, "answer": " Question: What are the two natural phenomena that degrade image capture which the proposed Dual Attention-in-Attention Model (DAiAM) aims to remove simultaneously?\n\nA) Raindrops and hail \nB) Rain streaks and snowflakes\nC) Rain streaks and raindrops\nD) Hail and snowflakes\n\nCorrect Answer: C) Rain streaks and raindrops\n\nExplanation: According to the documentation, rain streaks and rain drops are two natural phenomena which degrade image capture in different ways. The proposed DAiAM model includes two DAMs to remove both rain streaks and raindrops simultaneously."}, "30": {"documentation": {"title": "Multi-Document Summarization via Discriminative Summary Reranking", "source": "Xiaojun Wan, Ziqiang Cao, Furu Wei, Sujian Li and Ming Zhou", "docs_id": "1507.02062", "section": ["cs.CL"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Multi-Document Summarization via Discriminative Summary Reranking. Existing multi-document summarization systems usually rely on a specific summarization model (i.e., a summarization method with a specific parameter setting) to extract summaries for different document sets with different topics. However, according to our quantitative analysis, none of the existing summarization models can always produce high-quality summaries for different document sets, and even a summarization model with good overall performance may produce low-quality summaries for some document sets. On the contrary, a baseline summarization model may produce high-quality summaries for some document sets. Based on the above observations, we treat the summaries produced by different summarization models as candidate summaries, and then explore discriminative reranking techniques to identify high-quality summaries from the candidates for difference document sets. We propose to extract a set of candidate summaries for each document set based on an ILP framework, and then leverage Ranking SVM for summary reranking. Various useful features have been developed for the reranking process, including word-level features, sentence-level features and summary-level features. Evaluation results on the benchmark DUC datasets validate the efficacy and robustness of our proposed approach."}, "answer": " Question: According to the document, what is a key limitation of existing multi-document summarization systems that the proposed approach aims to address?\n\nA) They rely too much on hand-crafted features and cannot learn effectively from data.\n\nB) They use a single summarization model which may not produce good summaries for all document sets. \n\nC) They do not consider semantic relationships between documents when generating summaries.\n\nD) They are not able to handle summarizing large document collections with diverse topics.\n\nCorrect Answer: B) They use a single summarization model which may not produce good summaries for all document sets.\n\nExplanations: \nThe document states that \"none of the existing summarization models can always produce high-quality summaries for different document sets, and even a summarization model with good overall performance may produce low-quality summaries for some document sets.\" The proposed approach addresses this by treating summaries from different models as candidates and reranking them to identify the best summary for each document set."}, "31": {"documentation": {"title": "ST++: Make Self-training Work Better for Semi-supervised Semantic\n  Segmentation", "source": "Lihe Yang, Wei Zhuo, Lei Qi, Yinghuan Shi, Yang Gao", "docs_id": "2106.05095", "section": ["cs.CV"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "ST++: Make Self-training Work Better for Semi-supervised Semantic\n  Segmentation. In this paper, we investigate if we could make the self-training -- a simple but popular framework -- work better for semi-supervised segmentation. Since the core issue in semi-supervised setting lies in effective and efficient utilization of unlabeled data, we notice that increasing the diversity and hardness of unlabeled data is crucial to performance improvement. Being aware of this fact, we propose to adopt the most plain self-training scheme coupled with appropriate strong data augmentations on unlabeled data (namely ST) for this task, which surprisingly outperforms previous methods under various settings without any bells and whistles. Moreover, to alleviate the negative impact of the wrongly pseudo labeled images, we further propose an advanced self-training framework (namely ST++), that performs selective re-training via selecting and prioritizing the more reliable unlabeled images. As a result, the proposed ST++ boosts the performance of semi-supervised model significantly and surpasses existing methods by a large margin on the Pascal VOC 2012 and Cityscapes benchmark. Overall, we hope this straightforward and simple framework will serve as a strong baseline or competitor for future works. Code is available at https://github.com/LiheYoung/ST-PlusPlus."}, "answer": " Question: What method does the paper propose to alleviate the negative impact of wrongly pseudo labeled images in self-training for semi-supervised semantic segmentation?\n\nA) Using stronger data augmentations on unlabeled data \n\nB) Increasing the diversity and hardness of unlabeled data\n\nC) Performing selective re-training by prioritizing more reliable unlabeled images\n\nD) Adopting a plain self-training scheme with no modifications\n\nCorrect Answer: C\n\nExplanation: The paper proposes an advanced self-training framework called ST++ that performs selective re-training by selecting and prioritizing the more reliable unlabeled images in order to alleviate the negative impact of wrongly pseudo labeled images in self-training for semi-supervised semantic segmentation."}, "32": {"documentation": {"title": "How fine can fine-tuning be? Learning efficient language models", "source": "Evani Radiya-Dixit and Xin Wang", "docs_id": "2004.14129", "section": ["cs.CL", "cs.LG", "stat.ML"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "How fine can fine-tuning be? Learning efficient language models. State-of-the-art performance on language understanding tasks is now achieved with increasingly large networks; the current record holder has billions of parameters. Given a language model pre-trained on massive unlabeled text corpora, only very light supervised fine-tuning is needed to learn a task: the number of fine-tuning steps is typically five orders of magnitude lower than the total parameter count. Does this mean that fine-tuning only introduces small differences from the pre-trained model in the parameter space? If so, can one avoid storing and computing an entire model for each task? In this work, we address these questions by using Bidirectional Encoder Representations from Transformers (BERT) as an example. As expected, we find that the fine-tuned models are close in parameter space to the pre-trained one, with the closeness varying from layer to layer. We show that it suffices to fine-tune only the most critical layers. Further, we find that there are surprisingly many good solutions in the set of sparsified versions of the pre-trained model. As a result, fine-tuning of huge language models can be achieved by simply setting a certain number of entries in certain layers of the pre-trained parameters to zero, saving both task-specific parameter storage and computational cost."}, "answer": " Question: According to the paper, what allows efficient fine-tuning of large language models on downstream tasks?\n\nA) Only fine-tuning the most critical layers rather than the full model\nB) Finding many good solutions in sparsified versions of the pre-trained model  \nC) Setting a number of entries in certain layers to zero to save storage and computation\nD) Using models with billions of parameters that are pre-trained on massive datasets\n\nCorrect Answer: B\n\nExplanation: The paper finds that there are surprisingly many good solutions in the set of sparsified versions of the pre-trained model. This allows efficient fine-tuning by only modifying a subset of the full model's parameters."}, "33": {"documentation": {"title": "A Game-Theoretical Self-Adaptation Framework for Securing\n  Software-Intensive Systems", "source": "Mingyue Zhang, Nianyu Li, Sridhar Adepu, Eunsuk Kang, Zhi Jin", "docs_id": "2112.07588", "section": ["cs.SE", "cs.GT"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "A Game-Theoretical Self-Adaptation Framework for Securing\n  Software-Intensive Systems. The increasing prevalence of security attacks on software-intensive systems calls for new, effective methods for detecting and responding to these attacks. As one promising approach, game theory provides analytical tools for modeling the interaction between the system and the adversarial environment and designing reliable defense. In this paper, we propose an approach for securing software-intensive systems using a rigorous game-theoretical framework. First, a self-adaptation framework is deployed on a component-based software intensive system, which periodically monitors the system for anomalous behaviors. A learning-based method is proposed to detect possible on-going attacks on the system components and predict potential threats to components. Then, an algorithm is designed to automatically build a \\emph{Bayesian game} based on the system architecture (of which some components might have been compromised) once an attack is detected, in which the system components are modeled as independent players in the game. Finally, an optimal defensive policy is computed by solving the Bayesian game to achieve the best system utility, which amounts to minimizing the impact of the attack. We conduct two sets of experiments on two general benchmark tasks for security domain. Moreover, we systematically present a case study on a real-world water treatment testbed, i.e. the Secure Water Treatment System. Experiment results show the applicability and the effectiveness of our approach."}, "answer": " Here is a 4-option multiple choice question on the paper:\n\nQuestion: Which of the following is NOT a component of the proposed game-theoretical self-adaptation framework for securing software-intensive systems described in the paper?\n\nA) A learning-based method to detect ongoing attacks and predict threats to system components.\n\nB) Modeling system components as players in a Bayesian game to compute an optimal defensive policy. \n\nC) Periodically monitoring the system for anomalous behaviors using a self-adaptation framework.\n\nD) Using reinforcement learning to train the system's response to different attacks.\n\nCorrect Answer: D\n\nExplanation: The paper proposes a framework with three main components: 1) a self-adaptation framework to monitor the system, 2) a learning method to detect attacks, and 3) modeling the system as a Bayesian game to compute an optimal defense policy. Reinforcement learning to train the system's response is not discussed in the paper."}, "34": {"documentation": {"title": "Chittron: An Automatic Bangla Image Captioning System", "source": "Motiur Rahman, Nabeel Mohammed, Nafees Mansoor, Sifat Momen", "docs_id": "1809.00339", "section": ["cs.CL", "cs.CV"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Chittron: An Automatic Bangla Image Captioning System. Automatic image caption generation aims to produce an accurate description of an image in natural language automatically. However, Bangla, the fifth most widely spoken language in the world, is lagging considerably in the research and development of such domain. Besides, while there are many established data sets to related to image annotation in English, no such resource exists for Bangla yet. Hence, this paper outlines the development of \"Chittron\", an automatic image captioning system in Bangla. Moreover, to address the data set availability issue, a collection of 16,000 Bangladeshi contextual images has been accumulated and manually annotated in Bangla. This data set is then used to train a model which integrates a pre-trained VGG16 image embedding model with stacked LSTM layers. The model is trained to predict the caption when the input is an image, one word at a time. The results show that the model has successfully been able to learn a working language model and to generate captions of images quite accurately in many cases. The results are evaluated mainly qualitatively. However, BLEU scores are also reported. It is expected that a better result can be obtained with a bigger and more varied data set."}, "answer": " Here is a 4-option multiple choice question on the given text:\n\nQuestion: Which of the following statements is true about the image captioning system \"Chittron\" described in the text?\n\nA) It uses a data set of 10,000 images annotated in Bangla to train the model.\n\nB) It integrates a pre-trained ResNet model with stacked LSTM layers. \n\nC) The results are evaluated quantitatively using BLEU scores.\n\nD) It aims to produce captions for images in Bangla, which lacks resources in this domain.\n\nCorrect Answer: D\n\nExplanation: The text mentions that Chittron is an automatic image captioning system for Bangla, which lacks resources and lags behind in image captioning research. It uses a data set of 16,000 Bangla annotated images. The model integrates VGG16 image features with LSTM layers. Results are evaluated qualitatively but BLEU scores are also reported."}, "35": {"documentation": {"title": "Side-Channel Inference Attacks on Mobile Keypads using Smartwatches", "source": "Anindya Maiti, Murtuza Jadliwala, Jibo He, Igor Bilogrevic", "docs_id": "1710.03656", "section": ["cs.CR"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Side-Channel Inference Attacks on Mobile Keypads using Smartwatches. Smartwatches enable many novel applications and are fast gaining popularity. However, the presence of a diverse set of on-board sensors provides an additional attack surface to malicious software and services on these devices. In this paper, we investigate the feasibility of key press inference attacks on handheld numeric touchpads by using smartwatch motion sensors as a side-channel. We consider different typing scenarios, and propose multiple attack approaches to exploit the characteristics of the observed wrist movements for inferring individual key presses. Experimental evaluation using commercial off-the-shelf smartwatches and smartphones show that key press inference using smartwatch motion sensors is not only fairly accurate, but also comparable with similar attacks using smartphone motion sensors. Additionally, hand movements captured by a combination of both smartwatch and smartphone motion sensors yields better inference accuracy than either device considered individually."}, "answer": " Here is a 4-option multiple choice question on the given research paper summary:\n\nQuestion: Which of the following statements is true about the side-channel inference attacks on mobile keypads using smartwatches described in the research paper?\n\nA) The presence of diverse on-board sensors in smartwatches enables novel applications but does not provide any additional attack surface for malicious software.\n\nB) Experimental evaluation showed that key press inference using smartphone motion sensors is more accurate than using smartwatch motion sensors. \n\nC) The wrist movements captured by smartwatches alone are sufficient for fairly accurate key press inference attacks.\n\nD) Using a combination of both smartwatch and smartphone motion sensors provides better key press inference accuracy than either device alone.\n\nCorrect Answer: D) Using a combination of both smartwatch and smartphone motion sensors provides better key press inference accuracy than either device alone.\n\nExplanation: According to the research paper summary, experimental evaluation showed that key press inference using a combination of both smartwatch and smartphone motion sensors yields better accuracy than using either device individually. Option D summarizes this key finding from the paper. Options A, B and C are incorrect interpretations of the research results."}, "36": {"documentation": {"title": "iPiano: Inertial Proximal Algorithm for Non-Convex Optimization", "source": "Peter Ochs and Yunjin Chen and Thomas Brox and Thomas Pock", "docs_id": "1404.4805", "section": ["cs.CV", "math.OC"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "iPiano: Inertial Proximal Algorithm for Non-Convex Optimization. In this paper we study an algorithm for solving a minimization problem composed of a differentiable (possibly non-convex) and a convex (possibly non-differentiable) function. The algorithm iPiano combines forward-backward splitting with an inertial force. It can be seen as a non-smooth split version of the Heavy-ball method from Polyak. A rigorous analysis of the algorithm for the proposed class of problems yields global convergence of the function values and the arguments. This makes the algorithm robust for usage on non-convex problems. The convergence result is obtained based on the \\KL inequality. This is a very weak restriction, which was used to prove convergence for several other gradient methods. First, an abstract convergence theorem for a generic algorithm is proved, and, then iPiano is shown to satisfy the requirements of this theorem. Furthermore, a convergence rate is established for the general problem class. We demonstrate iPiano on computer vision problems: image denoising with learned priors and diffusion based image compression."}, "answer": " Question: Which of the following statements accurately summarizes a key contribution of the iPiano algorithm described in the paper?\n\nA) It combines forward-backward splitting with an inertial force to enable convergence guarantees for non-convex optimization problems.\n\nB) It uses the heavy ball method to optimize differentiable non-convex functions. \n\nC) It proves global convergence rates for non-smooth convex optimization problems.\n\nD) It shows how to apply diffusion based image compression using inertial proximal algorithms.\n\nCorrect Answer: A\n\nExplanation: The key contribution according to the documentation is that iPiano combines forward-backward splitting with an inertial force, allowing it to achieve global convergence guarantees for optimization problems involving both non-convex differentiable and convex non-differentiable functions."}, "37": {"documentation": {"title": "Disentangling 3D Pose in A Dendritic CNN for Unconstrained 2D Face\n  Alignment", "source": "Amit Kumar, Rama Chellappa", "docs_id": "1802.06713", "section": ["cs.CV"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Disentangling 3D Pose in A Dendritic CNN for Unconstrained 2D Face\n  Alignment. Heatmap regression has been used for landmark localization for quite a while now. Most of the methods use a very deep stack of bottleneck modules for heatmap classification stage, followed by heatmap regression to extract the keypoints. In this paper, we present a single dendritic CNN, termed as Pose Conditioned Dendritic Convolution Neural Network (PCD-CNN), where a classification network is followed by a second and modular classification network, trained in an end to end fashion to obtain accurate landmark points. Following a Bayesian formulation, we disentangle the 3D pose of a face image explicitly by conditioning the landmark estimation on pose, making it different from multi-tasking approaches. Extensive experimentation shows that conditioning on pose reduces the localization error by making it agnostic to face pose. The proposed model can be extended to yield variable number of landmark points and hence broadening its applicability to other datasets. Instead of increasing depth or width of the network, we train the CNN efficiently with Mask-Softmax Loss and hard sample mining to achieve upto $15\\%$ reduction in error compared to state-of-the-art methods for extreme and medium pose face images from challenging datasets including AFLW, AFW, COFW and IBUG."}, "answer": " Here is a multi-form question on the paper:\n\nQuestion: Which of the following statements is true about the Pose Conditioned Dendritic Convolution Neural Network (PCD-CNN) presented in the paper \"Disentangling 3D Pose in A Dendritic CNN for Unconstrained 2D Face Alignment\"?\n\nA) It uses a very deep stack of bottleneck modules for the heatmap classification stage.\n\nB) It trains the network with Mask-Softmax Loss and hard sample mining to improve performance. \n\nC) It is a multi-task learning approach that jointly predicts landmarks and 3D pose.\n\nD) It conditions landmark estimation on pose by using an explicit 3D pose disentangling formulation.\n\nCorrect Answer: D\n\nExplanation: According to the paper, PCD-CNN uses a dendritic architecture with two classification networks, where the second network is conditioned on pose to disentangle 3D pose explicitly. It does not use a deep stack of bottlenecks or multi-tasking. The network is trained with Mask-Softmax Loss and hard mining."}, "38": {"documentation": {"title": "Learning to Automatically Catch Potholes in Worldwide Road Scene Images", "source": "J. Javier Yebes, David Montero, Ignacio Arriola", "docs_id": "2105.07986", "section": ["cs.CV", "cs.LG", "eess.IV"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Learning to Automatically Catch Potholes in Worldwide Road Scene Images. Among several road hazards that are present in any paved way in the world, potholes are one of the most annoying and also involving higher maintenance costs. There exists an increasing interest on the automated detection of these hazards enabled by technological and research progress. Our research work tackled the challenge of pothole detection from images of real world road scenes. The main novelty resides on the application of the latest progress in AI to learn the visual appearance of potholes. We built a large dataset of images with pothole annotations. They contained road scenes from different cities in the world, taken with different cameras, vehicles and viewpoints under varied environmental conditions. Then, we fine-tuned four different object detection models based on Faster R-CNN and SSD deep neural networks. We achieved high average precision and the pothole detector was tested on the Nvidia DrivePX2 platform with GPGPU capability, which can be embedded on vehicles. Moreover, it was deployed on a real vehicle to notify the detected potholes to a given IoT platform as part of AUTOPILOT H2020 project."}, "answer": " Here is a multi-form question based on the given documentation:\n\nQuestion: Which of the following statements is true about the pothole detection system described in the documentation?\n\nA) It was trained on a dataset of road images from a single city under consistent lighting.\n\nB) It achieved low average precision when tested on the Nvidia DrivePX2 platform. \n\nC) It notified detected potholes to an IoT platform as part of the AUTOPILOT project.\n\nD) It used Faster R-CNN and SSD networks that were pretrained on ImageNet.\n\nCorrect Answer: C\n\nExplanation: \nThe documentation states that the pothole detection system was trained on images from different cities under varied conditions. It achieved high average precision on the DrivePX2 platform. The system notified detected potholes to an IoT platform as part of the AUTOPILOT project, which makes option C correct. The Faster R-CNN and SSD networks were fine-tuned rather than pretrained, so D is incorrect."}, "39": {"documentation": {"title": "Fast Incremental SVDD Learning Algorithm with the Gaussian Kernel", "source": "Hansi Jiang, Haoyu Wang, Wenhao Hu, Deovrat Kakde and Arin Chaudhuri", "docs_id": "1709.00139", "section": ["stat.ML", "cs.LG"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Fast Incremental SVDD Learning Algorithm with the Gaussian Kernel. Support vector data description (SVDD) is a machine learning technique that is used for single-class classification and outlier detection. The idea of SVDD is to find a set of support vectors that defines a boundary around data. When dealing with online or large data, existing batch SVDD methods have to be rerun in each iteration. We propose an incremental learning algorithm for SVDD that uses the Gaussian kernel. This algorithm builds on the observation that all support vectors on the boundary have the same distance to the center of sphere in a higher-dimensional feature space as mapped by the Gaussian kernel function. Each iteration involves only the existing support vectors and the new data point. Moreover, the algorithm is based solely on matrix manipulations; the support vectors and their corresponding Lagrange multiplier $\\alpha_i$'s are automatically selected and determined in each iteration. It can be seen that the complexity of our algorithm in each iteration is only $O(k^2)$, where $k$ is the number of support vectors. Experimental results on some real data sets indicate that FISVDD demonstrates significant gains in efficiency with almost no loss in either outlier detection accuracy or objective function value."}, "answer": " Here is a multi-form question on the SVDD incremental learning algorithm:\n\nQuestion: Which of the following statements is true about the proposed incremental SVDD learning algorithm with the Gaussian kernel?\n\nA) It involves recomputing the support vectors and their Lagrange multipliers \u03b1i's at each iteration.\n\nB) It has a complexity of O(n2) per iteration, where n is the number of data points. \n\nC) It is based on the observation that support vectors on the boundary have varying distances to the center.\n\nD) It only involves the existing support vectors and the new data point at each iteration.\n\nCorrect Answer: D\n\nExplanation: \nThe proposed incremental SVDD algorithm leverages the fact that boundary support vectors have the same distance to the center in feature space. It incrementally updates the model using only existing support vectors and the new data point in each iteration. This results in a complexity of O(k2) per iteration, where k is the number of support vectors. Options A, B and C are incorrect based on the details provided in the documentation."}, "40": {"documentation": {"title": "Scaling Properties of Deep Residual Networks", "source": "Alain-Sam Cohen, Rama Cont, Alain Rossier, Renyuan Xu", "docs_id": "2105.12245", "section": ["cs.LG", "cs.NA", "cs.NE", "math.NA", "stat.ML"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Scaling Properties of Deep Residual Networks. Residual networks (ResNets) have displayed impressive results in pattern recognition and, recently, have garnered considerable theoretical interest due to a perceived link with neural ordinary differential equations (neural ODEs). This link relies on the convergence of network weights to a smooth function as the number of layers increases. We investigate the properties of weights trained by stochastic gradient descent and their scaling with network depth through detailed numerical experiments. We observe the existence of scaling regimes markedly different from those assumed in neural ODE literature. Depending on certain features of the network architecture, such as the smoothness of the activation function, one may obtain an alternative ODE limit, a stochastic differential equation or neither of these. These findings cast doubts on the validity of the neural ODE model as an adequate asymptotic description of deep ResNets and point to an alternative class of differential equations as a better description of the deep network limit."}, "answer": " Here is a 4-option multiple choice question on the key findings from the abstract:\n\nQuestion: According to the abstract, which of the following statements is true about the scaling properties of deep residual networks trained with stochastic gradient descent?\n\nA) The weights always converge to a smooth function as network depth increases, matching the assumptions of neural ODE models.\n\nB) The network displays properties of a stochastic differential equation in the limit of large depth under certain conditions. \n\nC) The abstract recommends an alternative class of differential equations that better describe deep ResNets.\n\nD) Deep ResNets display the same scaling properties regardless of activation function smoothness.\n\nCorrect Answer: B\n\nExplanation: The abstract states that depending on network architecture features like activation function smoothness, deep ResNets may display properties of a stochastic differential equation in the limit of large depth. This matches option B. Option A is incorrect - the abstract says this convergence is not always observed. Option C proposes differential equations as better models but does not specify an alternative class. Option D contradicts the mention of activation function smoothness affecting scaling properties."}, "41": {"documentation": {"title": "DNN-Life: An Energy-Efficient Aging Mitigation Framework for Improving\n  the Lifetime of On-Chip Weight Memories in Deep Neural Network Hardware\n  Architectures", "source": "Muhammad Abdullah Hanif, Muhammad Shafique", "docs_id": "2101.12351", "section": ["cs.AR"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "DNN-Life: An Energy-Efficient Aging Mitigation Framework for Improving\n  the Lifetime of On-Chip Weight Memories in Deep Neural Network Hardware\n  Architectures. Negative Biased Temperature Instability (NBTI)-induced aging is one of the critical reliability threats in nano-scale devices. This paper makes the first attempt to study the NBTI aging in the on-chip weight memories of deep neural network (DNN) hardware accelerators, subjected to complex DNN workloads. We propose DNN-Life, a specialized aging analysis and mitigation framework for DNNs, which jointly exploits hardware- and software-level knowledge to improve the lifetime of a DNN weight memory with reduced energy overhead. At the software-level, we analyze the effects of different DNN quantization methods on the distribution of the bits of weight values. Based on the insights gained from this analysis, we propose a micro-architecture that employs low-cost memory-write (and read) transducers to achieve an optimal duty-cycle at run time in the weight memory cells, thereby balancing their aging. As a result, our DNN-Life framework enables efficient aging mitigation of weight memory of the given DNN hardware at minimal energy overhead during the inference process."}, "answer": " Here is a 4-option multiple choice question on the DNN-Life paper:\n\nQuestion: Which of the following statements is true about the proposed DNN-Life framework in the paper?\n\nA) It mitigates aging in DNN weight memories by reducing the voltage supplied to them \n\nB) It balances the aging across different weight memory cells by optimizing their duty cycles at runtime\n\nC) It employs error correction codes to detect and correct aging-induced faults in weight memories\n\nD) It replicates weight values across multiple memory cells to provide redundancy against aging faults\n\nCorrect Answer: B\n\nExplanation: \nThe paper proposes DNN-Life, a framework that mitigates aging in DNN weight memories by optimally balancing the duty cycles of the memory cells at runtime using low-cost memory transducers. This balances the aging across cells to improve the overall lifetime of the weight memory. Options A, C and D describe other common techniques for mitigating aging faults, but are not part of the proposed DNN-Life framework."}, "42": {"documentation": {"title": "A Two-stage Unsupervised Approach for Low light Image Enhancement", "source": "Junjie Hu, Xiyue Guo, Junfeng Chen, Guanqi Liang, Fuqin Deng and Tin\n  lun Lam", "docs_id": "2010.09316", "section": ["cs.CV"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "A Two-stage Unsupervised Approach for Low light Image Enhancement. As vision based perception methods are usually built on the normal light assumption, there will be a serious safety issue when deploying them into low light environments. Recently, deep learning based methods have been proposed to enhance low light images by penalizing the pixel-wise loss of low light and normal light images. However, most of them suffer from the following problems: 1) the need of pairs of low light and normal light images for training, 2) the poor performance for dark images, 3) the amplification of noise. To alleviate these problems, in this paper, we propose a two-stage unsupervised method that decomposes the low light image enhancement into a pre-enhancement and a post-refinement problem. In the first stage, we pre-enhance a low light image with a conventional Retinex based method. In the second stage, we use a refinement network learned with adversarial training for further improvement of the image quality. The experimental results show that our method outperforms previous methods on four benchmark datasets. In addition, we show that our method can significantly improve feature points matching and simultaneous localization and mapping in low light conditions."}, "answer": " Here is a multi-form question based on the given text:\n\nQuestion: Which of the following is NOT mentioned as a problem with existing deep learning based low light image enhancement methods?\n\nA) They require paired low light and normal light images for training.\n\nB) They perform poorly on very dark images. \n\nC) They tend to amplify noise during enhancement.\n\nD) They are computationally inefficient.\n\nCorrect Answer: D) They are computationally inefficient.\n\nExplanation: The text mentions the need for paired training data, poor performance on dark images, and noise amplification as problems with existing methods, but does not state computational inefficiency as an issue."}, "43": {"documentation": {"title": "Multimodal Approach for Metadata Extraction from German Scientific\n  Publications", "source": "Azeddine Bouabdallah, Jorge Gavilan, Jennifer Gerbl and Prayuth\n  Patumcharoenpol", "docs_id": "2111.05736", "section": ["cs.IR", "cs.CV", "cs.LG"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Multimodal Approach for Metadata Extraction from German Scientific\n  Publications. Nowadays, metadata information is often given by the authors themselves upon submission. However, a significant part of already existing research papers have missing or incomplete metadata information. German scientific papers come in a large variety of layouts which makes the extraction of metadata a non-trivial task that requires a precise way to classify the metadata extracted from the documents. In this paper, we propose a multimodal deep learning approach for metadata extraction from scientific papers in the German language. We consider multiple types of input data by combining natural language processing and image vision processing. This model aims to increase the overall accuracy of metadata extraction compared to other state-of-the-art approaches. It enables the utilization of both spatial and contextual features in order to achieve a more reliable extraction. Our model for this approach was trained on a dataset consisting of around 8800 documents and is able to obtain an overall F1-score of 0.923."}, "answer": " Question: What is the main goal of the multimodal deep learning approach proposed in the paper for extracting metadata from German scientific publications?\n\nA) To extract metadata information that was intentionally left out by the authors upon submission.\n\nB) To handle the large variety of layouts in German scientific papers which makes metadata extraction challenging. \n\nC) To utilize both spatial and contextual features to increase the overall accuracy of metadata extraction.\n\nD) To classify the metadata extracted from scientific documents in a more precise way.\n\nCorrect Answer: C\n\nExplanation: The paper proposes a multimodal deep learning approach that combines natural language processing and image vision processing to increase the overall accuracy of extracting metadata from German scientific publications compared to other approaches. It aims to utilize both spatial and contextual features to achieve more reliable extraction."}, "44": {"documentation": {"title": "Physics-Driven Regularization of Deep Neural Networks for Enhanced\n  Engineering Design and Analysis", "source": "Mohammad Amin Nabian, Hadi Meidani", "docs_id": "1810.05547", "section": ["cs.LG", "cs.CE", "cs.NA", "math.AP", "math.NA", "stat.ML"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Physics-Driven Regularization of Deep Neural Networks for Enhanced\n  Engineering Design and Analysis. In this paper, we introduce a physics-driven regularization method for training of deep neural networks (DNNs) for use in engineering design and analysis problems. In particular, we focus on prediction of a physical system, for which in addition to training data, partial or complete information on a set of governing laws is also available. These laws often appear in the form of differential equations, derived from first principles, empirically-validated laws, or domain expertise, and are usually neglected in data-driven prediction of engineering systems. We propose a training approach that utilizes the known governing laws and regularizes data-driven DNN models by penalizing divergence from those laws. The first two numerical examples are synthetic examples, where we show that in constructing a DNN model that best fits the measurements from a physical system, the use of our proposed regularization results in DNNs that are more interpretable with smaller generalization errors, compared to other common regularization methods. The last two examples concern metamodeling for a random Burgers' system and for aerodynamic analysis of passenger vehicles, where we demonstrate that the proposed regularization provides superior generalization accuracy compared to other common alternatives."}, "answer": " Here is a multi-form question based on the given text:\n\nQuestion: Which of the following statements accurately describes a key contribution of the paper?\n\nA) The paper introduces a physics-driven regularization method that penalizes divergence from known governing laws, resulting in more interpretable DNNs with smaller generalization error.\n\nB) The paper shows that using common regularization methods like L1 and L2 regularization results in the best performance for DNNs used in engineering design.\n\nC) The paper demonstrates that DNNs without any physics-driven regularization perform just as well as those with the proposed method.\n\nD) The paper focuses on prediction tasks where no physics-based governing laws are available, and shows the limitations of DNNs in these cases.\n\nCorrect Answer: A\n\nThe paper introduces a physics-driven regularization method that penalizes divergence from known governing laws, resulting in more interpretable DNNs with smaller generalization error."}, "45": {"documentation": {"title": "Data Driven Validation Framework for Multi-agent Activity-based Models", "source": "Jan Drchal, Michal \\v{C}ertick\\'y, Michal Jakob", "docs_id": "1502.07601", "section": ["cs.MA"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Data Driven Validation Framework for Multi-agent Activity-based Models. Activity-based models, as a specific instance of agent-based models, deal with agents that structure their activity in terms of (daily) activity schedules. An activity schedule consists of a sequence of activity instances, each with its assigned start time, duration and location, together with transport modes used for travel between subsequent activity locations. A critical step in the development of simulation models is validation. Despite the growing importance of activity-based models in modelling transport and mobility, there has been so far no work focusing specifically on statistical validation of such models. In this paper, we propose a six-step Validation Framework for Activity-based Models (VALFRAM) that allows exploiting historical real-world data to assess the validity of activity-based models. The framework compares temporal and spatial properties and the structure of activity schedules against real-world travel diaries and origin-destination matrices. We confirm the usefulness of the framework on three real-world activity-based transport models."}, "answer": " Question: What is a key component of the proposed VALFRAM validation framework for activity-based models?\n\nA) Comparing activity schedules to real-world origin-destination matrices.\n\nB) Assessing the realism of agent decision-making rules. \n\nC) Analyzing the validity of transport mode choice models.\n\nD) Comparing temporal and spatial properties of activity schedules against real-world travel diaries.\n\nCorrect Answer: D\n\nExplanation: According to the documentation, a key component of the proposed VALFRAM validation framework is comparing temporal and spatial properties and the structure of activity schedules from the model against real-world travel diaries. While origin-destination matrices are also used, the main validation is done by comparing against travel diaries. The documentation does not mention analyzing agent decision rules or transport mode choice models as part of VALFRAM."}, "46": {"documentation": {"title": "PoseTrack: A Benchmark for Human Pose Estimation and Tracking", "source": "Mykhaylo Andriluka, Umar Iqbal, Eldar Insafutdinov, Leonid Pishchulin,\n  Anton Milan, Juergen Gall and Bernt Schiele", "docs_id": "1710.10000", "section": ["cs.CV"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "PoseTrack: A Benchmark for Human Pose Estimation and Tracking. Human poses and motions are important cues for analysis of videos with people and there is strong evidence that representations based on body pose are highly effective for a variety of tasks such as activity recognition, content retrieval and social signal processing. In this work, we aim to further advance the state of the art by establishing \"PoseTrack\", a new large-scale benchmark for video-based human pose estimation and articulated tracking, and bringing together the community of researchers working on visual human analysis. The benchmark encompasses three competition tracks focusing on i) single-frame multi-person pose estimation, ii) multi-person pose estimation in videos, and iii) multi-person articulated tracking. To facilitate the benchmark and challenge we collect, annotate and release a new %large-scale benchmark dataset that features videos with multiple people labeled with person tracks and articulated pose. A centralized evaluation server is provided to allow participants to evaluate on a held-out test set. We envision that the proposed benchmark will stimulate productive research both by providing a large and representative training dataset as well as providing a platform to objectively evaluate and compare the proposed methods. The benchmark is freely accessible at https://posetrack.net."}, "answer": " Question: What is the main goal of the PoseTrack benchmark described in the passage?\n\nA) To advance the state of the art in human pose estimation and tracking by providing a large training dataset and evaluation platform.\n\nB) To focus on single-frame multi-person pose estimation as the primary task. \n\nC) To collect videos of people for activity recognition and social signal processing.\n\nD) To provide an annotated dataset of videos with a centralized test server.\n\nCorrect Answer: A\n\nExplanation: The passage states that the goal of PoseTrack is \"to further advance the state of the art by establishing a new large-scale benchmark for video-based human pose estimation and articulated tracking.\" It provides a large training dataset and evaluation server to stimulate research in this area."}, "47": {"documentation": {"title": "MReD: A Meta-Review Dataset for Controllable Text Generation", "source": "Chenhui Shen, Liying Cheng, Ran Zhou, Lidong Bing, Yang You, Luo Si", "docs_id": "2110.07474", "section": ["cs.CL"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "MReD: A Meta-Review Dataset for Controllable Text Generation. When directly using existing text generation datasets for controllable generation, we are facing the problem of not having the domain knowledge and thus the aspects that could be controlled are limited.A typical example is when using CNN/Daily Mail dataset for controllable text summarization, there is no guided information on the emphasis of summary sentences. A more useful text generator should leverage both the input text and control variables to guide the generation, which can only be built with deep understanding of the domain knowledge. Motivated by this vi-sion, our paper introduces a new text generation dataset, named MReD. Our new dataset consists of 7,089 meta-reviews and all its 45k meta-review sentences are manually annotated as one of the carefully defined 9 categories, including abstract, strength, decision, etc. We present experimental results on start-of-the-art summarization models, and propose methods for controlled generation on both extractive and abstractive models using our annotated data. By exploring various settings and analaysing the model behavior with respect to the control inputs, we demonstrate the challenges and values of our dataset. MReD allows us to have a better understanding of the meta-review corpora and enlarge the research room for controllable text generation."}, "answer": " Here is a multi-form question on the MReD dataset documentation:\n\nQuestion: Which of the following is a key motivation behind creating the MReD dataset?\n\nA) Existing text generation datasets do not have enough text data to train models well.\n\nB) Current text generation models do not allow for controllable generation based on domain knowledge. \n\nC) Text generation models trained on news articles do not work well for generating meta-reviews.\n\nD) There are no datasets available for training abstractive summarization models.\n\nCorrect Answer: B\n\nExplanation: The documentation states that a key motivation for MReD is that \"When directly using existing text generation datasets for controllable generation, we are facing the problem of not having the domain knowledge and thus the aspects that could be controlled are limited.\" So a lack of domain knowledge/controllable aspects is a key motivation, making B the correct answer."}, "48": {"documentation": {"title": "Practical Deep Raw Image Denoising on Mobile Devices", "source": "Yuzhi Wang, Haibin Huang, Qin Xu, Jiaming Liu, Yiqun Liu, Jue Wang", "docs_id": "2010.06935", "section": ["eess.IV", "cs.CV"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Practical Deep Raw Image Denoising on Mobile Devices. Deep learning-based image denoising approaches have been extensively studied in recent years, prevailing in many public benchmark datasets. However, the stat-of-the-art networks are computationally too expensive to be directly applied on mobile devices. In this work, we propose a light-weight, efficient neural network-based raw image denoiser that runs smoothly on mainstream mobile devices, and produces high quality denoising results. Our key insights are twofold: (1) by measuring and estimating sensor noise level, a smaller network trained on synthetic sensor-specific data can out-perform larger ones trained on general data; (2) the large noise level variation under different ISO settings can be removed by a novel k-Sigma Transform, allowing a small network to efficiently handle a wide range of noise levels. We conduct extensive experiments to demonstrate the efficiency and accuracy of our approach. Our proposed mobile-friendly denoising model runs at ~70 milliseconds per megapixel on Qualcomm Snapdragon 855 chipset, and it is the basis of the night shot feature of several flagship smartphones released in 2019."}, "answer": " Question: Which of the following statements best summarizes the key insights of the proposed mobile-friendly image denoising model?\n\nA) By using larger networks trained on more diverse data, the model can handle a wide range of noise levels efficiently.\n\nB) By estimating sensor noise levels, a smaller network trained on sensor-specific data can outperform larger networks trained on general data. \n\nC) By removing ISO noise variation with a k-Sigma Transform, a small network can handle different noise levels despite limited training data.\n\nD) By focusing on computational efficiency, the model sacrifices denoising accuracy compared to state-of-the-art methods.\n\nCorrect Answer: C\n\nExplanation: The key insights of the proposed model are that 1) estimating sensor noise allows a smaller network trained on sensor-specific data to outperform larger networks, and 2) the k-Sigma Transform removes noise variation across ISO levels, allowing a small network to handle a wide range of noise efficiently despite limited training data."}, "49": {"documentation": {"title": "Proving Equivalence Between Complex Expressions Using Graph-to-Sequence\n  Neural Models", "source": "Steve Kommrusch, Th\\'eo Barollet and Louis-No\\\"el Pouchet", "docs_id": "2106.02452", "section": ["cs.PL", "cs.LG"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Proving Equivalence Between Complex Expressions Using Graph-to-Sequence\n  Neural Models. We target the problem of provably computing the equivalence between two complex expression trees. To this end, we formalize the problem of equivalence between two such programs as finding a set of semantics-preserving rewrite rules from one into the other, such that after the rewrite the two programs are structurally identical, and therefore trivially equivalent.We then develop a graph-to-sequence neural network system for program equivalence, trained to produce such rewrite sequences from a carefully crafted automatic example generation algorithm. We extensively evaluate our system on a rich multi-type linear algebra expression language, using arbitrary combinations of 100+ graph-rewriting axioms of equivalence. Our machine learning system guarantees correctness for all true negatives, and ensures 0 false positive by design. It outputs via inference a valid proof of equivalence for 93% of the 10,000 equivalent expression pairs isolated for testing, using up to 50-term expressions. In all cases, the validity of the sequence produced and therefore the provable assertion of program equivalence is always computable, in negligible time."}, "answer": " Here is a 4-option multiple choice question on the paper:\n\nQuestion: Which of the following statements is true about the graph-to-sequence neural network system developed in the paper for proving equivalence between complex expressions?\n\nA) It is trained to produce rewrite sequences that transform one expression tree into another structurally identical one. \n\nB) It guarantees correctness for all true positives and ensures no false negatives.\n\nC) It outputs a valid proof of equivalence for all 10,000 test expression pairs.\n\nD) It can prove equivalence between expressions with up to 50 terms in negligible time.\n\nCorrect Answer: A\n\nExplanation: Option A is correct according to the passage which states the system is \"trained to produce such rewrite sequences from one into the other, such that after the rewrite the two programs are structurally identical, and therefore trivially equivalent\". Options B, C and D are incorrect based on details in the passage - the system guarantees no false positives (not true positives), proves equivalence for 93% of test pairs (not 100%), and handles up to 50-term expressions (not proves equivalence in negligible time)."}, "50": {"documentation": {"title": "Near-Deterministic Inference of AS Relationships", "source": "Yuval Shavitt, Eran Shir, Udi Weinsberg", "docs_id": "0711.4562", "section": ["cs.NI"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Near-Deterministic Inference of AS Relationships. The discovery of Autonomous Systems (ASes) interconnections and the inference of their commercial Type-of-Relationships (ToR) has been extensively studied during the last few years. The main motivation is to accurately calculate AS-level paths and to provide better topological view of the Internet. An inherent problem in current algorithms is their extensive use of heuristics. Such heuristics incur unbounded errors which are spread over all inferred relationships. We propose a near-deterministic algorithm for solving the ToR inference problem. Our algorithm uses as input the Internet core, which is a dense sub-graph of top-level ASes. We test several methods for creating such a core and demonstrate the robustness of the algorithm to the core's size and density, the inference period, and errors in the core. We evaluate our algorithm using AS-level paths collected from RouteViews BGP paths and DIMES traceroute measurements. Our proposed algorithm deterministically infers over 95% of the approximately 58,000 AS topology links. The inference becomes stable when using a week worth of data and as little as 20 ASes in the core. The algorithm infers 2-3 times more peer-to-peer relationships in edges discovered only by DIMES than in RouteViews edges, validating the DIMES promise to discover periphery AS edges."}, "answer": " Question: What is the main motivation for accurately calculating AS-level paths and providing a better topological view of the Internet according to the paper?\n\nA) To reduce the use of heuristics in current algorithms which incur unbounded errors.\n\nB) To discover Autonomous Systems interconnections and infer their commercial Type-of-Relationships. \n\nC) To test methods for creating a dense sub-graph of top-level ASes known as the Internet core.\n\nD) To provide an accurate topological view of the Internet and calculate AS-level paths.\n\nCorrect Answer: D\n\nExplanation: According to the paper, \"The main motivation is to accurately calculate AS-level paths and to provide better topological view of the Internet.\" While reducing errors, discovering AS relationships, and testing methods to create the Internet core are discussed, the main motivation stated is to provide a better topological view and calculate AS-level paths."}, "51": {"documentation": {"title": "Growing 3D Artefacts and Functional Machines with Neural Cellular\n  Automata", "source": "Shyam Sudhakaran, Djordje Grbic, Siyan Li, Adam Katona, Elias Najarro,\n  Claire Glanois, Sebastian Risi", "docs_id": "2103.08737", "section": ["cs.LG"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Growing 3D Artefacts and Functional Machines with Neural Cellular\n  Automata. Neural Cellular Automata (NCAs) have been proven effective in simulating morphogenetic processes, the continuous construction of complex structures from very few starting cells. Recent developments in NCAs lie in the 2D domain, namely reconstructing target images from a single pixel or infinitely growing 2D textures. In this work, we propose an extension of NCAs to 3D, utilizing 3D convolutions in the proposed neural network architecture. Minecraft is selected as the environment for our automaton since it allows the generation of both static structures and moving machines. We show that despite their simplicity, NCAs are capable of growing complex entities such as castles, apartment blocks, and trees, some of which are composed of over 3,000 blocks. Additionally, when trained for regeneration, the system is able to regrow parts of simple functional machines, significantly expanding the capabilities of simulated morphogenetic systems. The code for the experiment in this paper can be found at: https://github.com/real-itu/3d-artefacts-nca."}, "answer": " Here is a multi-form question based on the given text:\n\nQuestion: Which of the following statements is true about the neural cellular automata (NCA) system described in the paper?\n\nA) It utilizes 2D convolutions to grow 3D structures in Minecraft.\n\nB) It is only capable of reconstructing 2D target images from a single pixel. \n\nC) It has been used to grow complex 3D structures composed of over 3,000 blocks in Minecraft.\n\nD) It cannot regenerate parts of simple functional machines.\n\nCorrect Answer: C\n\nExplanation: According to the text, the NCA system uses 3D convolutions to grow 3D structures in Minecraft. It has been used to grow complex 3D structures like castles and apartment blocks composed of over 3,000 blocks, showing it is capable of more than just reconstructing 2D images. The text also states it can regenerate parts of simple functional machines when trained for regeneration."}, "52": {"documentation": {"title": "Frequency-Domain Group-based Shrinkage Estimators for UWB Systems", "source": "Sheng Li, Rodrigo C. de Lamare and Martin Haardt", "docs_id": "1304.5817", "section": ["cs.IT", "math.IT"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Frequency-Domain Group-based Shrinkage Estimators for UWB Systems. In this work, we propose low-complexity adaptive biased estimation algorithms, called group-based shrinkage estimators (GSEs), for parameter estimation and interference suppression scenarios with mechanisms to automatically adjust the shrinkage factors. The proposed estimation algorithms divide the target parameter vector into a number of groups and adaptively calculate one shrinkage factor for each group. GSE schemes improve the performance of the conventional least squares (LS) estimator in terms of the mean-squared error (MSE), while requiring a very modest increase in complexity. An MSE analysis is presented which indicates the lower bounds of the GSE schemes with different group sizes. We prove that our proposed schemes outperform the biased estimation with only one shrinkage factor and the best performance of GSE can be obtained with the maximum number of groups. Then, we consider an application of the proposed algorithms to single-carrier frequency-domain equalization (SC-FDE) of direct-sequence ultra-wideband (DS-UWB) systems, in which the structured channel estimation (SCE) algorithm and the frequency domain receiver employ the GSE. The simulation results show that the proposed algorithms significantly outperform the conventional unbiased estimator in the analyzed scenarios."}, "answer": " Here is a 4-option multiple choice question on the paper:\n\nQuestion: Which of the following statements is true about the group-based shrinkage estimators (GSEs) proposed in the paper?\n\nA) GSE divides the parameter vector into groups and calculates multiple shrinkage factors, one for each group. This improves MSE performance compared to using a single shrinkage factor. \n\nB) GSE is guaranteed to achieve the minimum MSE compared to other biased estimators according to the theoretical analysis.\n\nC) The best GSE performance is obtained when the number of groups is minimized according to the proofs in the paper.\n\nD) GSE has higher complexity than the conventional LS estimator but provides no MSE improvement.\n\nCorrect Answer: A\n\nExplanation: According to the paper, GSE divides the parameter vector into groups and calculates a shrinkage factor for each group. This is shown to improve MSE compared to using a single shrinkage factor across all parameters. However, GSE is not guaranteed to achieve minimum MSE compared to all other biased estimators. The paper also proves that maximum number of groups provides the best GSE performance, not minimum number of groups. Finally, GSE does provide MSE improvement over LS estimator despite increased complexity."}, "53": {"documentation": {"title": "MBNet: MOS Prediction for Synthesized Speech with Mean-Bias Network", "source": "Yichong Leng, Xu Tan, Sheng Zhao, Frank Soong, Xiang-Yang Li, Tao Qin", "docs_id": "2103.00110", "section": ["cs.SD", "eess.AS"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "MBNet: MOS Prediction for Synthesized Speech with Mean-Bias Network. Mean opinion score (MOS) is a popular subjective metric to assess the quality of synthesized speech, and usually involves multiple human judges to evaluate each speech utterance. To reduce the labor cost in MOS test, multiple methods have been proposed to automatically predict MOS scores. To our knowledge, for a speech utterance, all previous works only used the average of multiple scores from different judges as the training target and discarded the score of each individual judge, which did not well exploit the precious MOS training data. In this paper, we propose MBNet, a MOS predictor with a mean subnet and a bias subnet to better utilize every judge score in MOS datasets, where the mean subnet is used to predict the mean score of each utterance similar to that in previous works, and the bias subnet to predict the bias score (the difference between the mean score and each individual judge score) and capture the personal preference of individual judges. Experiments show that compared with MOSNet baseline that only leverages mean score for training, MBNet improves the system-level spearmans rank correlation co-efficient (SRCC) by 2.9% on VCC 2018 dataset and 6.7% on VCC 2016 dataset."}, "answer": " Here is a 4-option multiple choice question on the document:\n\nQuestion: What does MBNet use to better utilize the scores from individual judges compared to previous MOS prediction methods according to the document?\n\nA) It uses only the average score across judges as the target, ignoring individual judge scores.\n\nB) It trains two networks - one to predict the mean score across judges, and another to predict the bias or difference between the mean and each judge's score. \n\nC) It trains a single network to predict scores from each individual judge.\n\nD) It trains a network to predict the full distribution of scores rather than just the mean.\n\nCorrect Answer: B\n\nExplanation: The document states that previous works used only the average score as the target, while MBNet uses a mean subnet to predict the average score and a separate bias subnet to predict the difference between the average and each individual score, thus better utilizing the individual scores."}, "54": {"documentation": {"title": "Flow Motifs in Interaction Networks", "source": "Chrysanthi Kosyfaki, Nikos Mamoulis, Evaggelia Pitoura, Panayiotis\n  Tsaparas", "docs_id": "1810.08408", "section": ["cs.SI"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Flow Motifs in Interaction Networks. Many real-world phenomena are best represented as interaction networks with dynamic structures (e.g., transaction networks, social networks, traffic networks). Interaction networks capture flow of data which is transferred between their vertices along a timeline. Analyzing such networks is crucial toward comprehend- ing processes in them. A typical analysis task is the finding of motifs, which are small subgraph patterns that repeat themselves in the network. In this paper, we introduce network flow motifs, a novel type of motifs that model significant flow transfer among a set of vertices within a constrained time window. We design an algorithm for identifying flow motif instances in a large graph. Our algorithm can be easily adapted to find the top-k instances of maximal flow. In addition, we design a dynamic programming module that finds the instance with the maximum flow. We evaluate the performance of the algorithm on three real datasets and identify flow motifs which are significant for these graphs. Our results show that our algorithm is scalable and that the real networks indeed include interesting motifs, which appear much more frequently than in randomly generated networks having similar characteristics."}, "answer": " Here is a 4-option multiple choice question on the paper:\n\nQuestion: Which of the following statements is true about the flow motifs identified in the paper?\n\nA) Flow motifs are subgraph patterns that appear much more frequently in real-world interaction networks compared to random networks.\n\nB) The algorithm proposed in the paper cannot find flow motif instances with maximum flow. \n\nC) The paper only evaluates the algorithm on synthetic datasets, not real datasets.\n\nD) Flow motifs model insignificant flow transfer among vertices over long time periods.\n\nCorrect Answer: A\n\nExplanation: According to the paper, flow motifs are subgraph patterns that repeat themselves and appear much more frequently in real interaction networks compared to randomly generated networks with similar characteristics. The paper states that their algorithm can identify motifs with maximum flow using dynamic programming. It also evaluates the algorithm on three real-world datasets and identifies meaningful motifs in them. Flow motifs model significant flow transfer among vertices within constrained time windows, not over long periods."}, "55": {"documentation": {"title": "A hybrid algorithm based on Community Detection and Multi-Attribute\n  Decision-Making for Influence Maximization", "source": "Masoud Jalayer, Morvarid Azheian, Mehrdad Mohammad Ali Kermani", "docs_id": "2105.09507", "section": ["cs.SI"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "A hybrid algorithm based on Community Detection and Multi-Attribute\n  Decision-Making for Influence Maximization. The influence maximization problem is trying to identify a set of K nodes by which the spread of influence, diseases, or information is maximized. The optimization of influence by finding such a set is an NP-hard problem and a key issue in analyzing complex networks. In this paper, a new greedy and hybrid approach based on a community detection algorithm and a MADM technique (TOPSIS) is proposed to cope with the problem, called, Greedy TOPSIS and Community-Based (GTaCB) algorithm. The paper concisely introduces community detection and the TOPSIS technique, then it presents the pseudo-code of the proposed algorithm. Afterward, it compares the performance of the solution which is found by GTaCB with some well-known greedy algorithms, based on Degree Centrality, Closeness Centrality, Betweenness Centrality, PageRank as well as TOPSIS, from two aspects: diffusion quality and diffusion speed. In order to evaluate the performance of GTaCB, computational experiments on nine different types of real-world networks are provided. The tests are conducted via one of the renowned epidemic diffusion models, namely, Susceptible-Infected-Recovered (SIR) model. The simulations exhibit that in most of the cases the proposed algorithm significantly outperforms the others, chiefly as the number of initial nodes or probability of infection increases."}, "answer": " Here is a multi-form question based on the given text:\n\nQuestion: Which of the following statements best describes the main contribution of the paper?\n\nA) It proposes a new community detection algorithm based on TOPSIS for influence maximization.\n\nB) It shows that the influence maximization problem can be solved optimally in polynomial time using a greedy algorithm. \n\nC) It introduces a hybrid algorithm called GTaCB that combines community detection and TOPSIS for influence maximization.\n\nD) It proves that the SIR model is the best diffusion model for evaluating influence maximization algorithms.\n\nCorrect Answer: C\n\nExplanation: The paper proposes a new hybrid algorithm called GTaCB that combines community detection and the MADM technique TOPSIS to address the influence maximization problem. It does not propose a new community detection algorithm itself. The influence maximization problem is NP-hard, not solvable in polynomial time. And the paper uses the SIR model to evaluate algorithms, but does not claim it is the best diffusion model."}, "56": {"documentation": {"title": "An Attention-Based Word-Level Interaction Model: Relation Detection for\n  Knowledge Base Question Answering", "source": "Hongzhi Zhang, Guandong Xu, Xiao Liang, Tinglei Huang and Kun fu", "docs_id": "1801.09893", "section": ["cs.CL"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "An Attention-Based Word-Level Interaction Model: Relation Detection for\n  Knowledge Base Question Answering. Relation detection plays a crucial role in Knowledge Base Question Answering (KBQA) because of the high variance of relation expression in the question. Traditional deep learning methods follow an encoding-comparing paradigm, where the question and the candidate relation are represented as vectors to compare their semantic similarity. Max- or average- pooling operation, which compresses the sequence of words into fixed-dimensional vectors, becomes the bottleneck of information. In this paper, we propose to learn attention-based word-level interactions between questions and relations to alleviate the bottleneck issue. Similar to the traditional models, the question and relation are firstly represented as sequences of vectors. Then, instead of merging the sequence into a single vector with pooling operation, soft alignments between words from the question and the relation are learned. The aligned words are subsequently compared with the convolutional neural network (CNN) and the comparison results are merged finally. Through performing the comparison on low-level representations, the attention-based word-level interaction model (ABWIM) relieves the information loss issue caused by merging the sequence into a fixed-dimensional vector before the comparison. The experimental results of relation detection on both SimpleQuestions and WebQuestions datasets show that ABWIM achieves state-of-the-art accuracy, demonstrating its effectiveness."}, "answer": " Here is a 4-option multiple choice question on the document:\n\nQuestion: Which of the following statements best describes the main contribution of the Attention-Based Word-Level Interaction Model (ABWIM) for relation detection in knowledge base question answering?\n\nA) ABWIM uses max-pooling and average-pooling to compress the question and relation into fixed-length vectors before comparison.\n\nB) ABWIM compares the question and relation on the word-level using soft alignments and CNN rather than relying on vector representations. \n\nC) ABWIM represents the question and relation as sequences of vectors and compares their similarity using cosine distance.\n\nD) ABWIM encodes the question and candidate relations into vectors and selects the relation vector closest to the question vector.\n\nCorrect Answer: B\n\nExplanation: The key contribution of ABWIM is performing word-level comparisons between the question and relation using soft alignments and CNN rather than relying on merged vector representations. This helps alleviate information loss compared to approaches that merge the sequences before comparison."}, "57": {"documentation": {"title": "On Controller Design for Systems on Manifolds in Euclidean Space", "source": "Dong Eui Chang", "docs_id": "1807.03475", "section": ["math.OC", "cs.RO", "cs.SY"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "On Controller Design for Systems on Manifolds in Euclidean Space. A new method is developed to design controllers in Euclidean space for systems defined on manifolds. The idea is to embed the state-space manifold $M$ of a given control system into some Euclidean space $\\mathbb R^n$, extend the system from $M$ to the ambient space $\\mathbb R^n$, and modify it outside $M$ to add transversal stability to $M$ in the final dynamics in $\\mathbb R^n$. Controllers are designed for the final system in the ambient space $\\mathbb R^n$. Then, their restriction to $M$ produces controllers for the original system on $M$. This method has the merit that only one single global Cartesian coordinate system in the ambient space $\\mathbb R^n$ is used for controller synthesis, and any controller design method in $\\mathbb R^n$, such as the linearization method, can be globally applied for the controller synthesis. The proposed method is successfully applied to the tracking problem for the following two benchmark systems: the fully actuated rigid body system and the quadcopter drone system."}, "answer": " Here is a multi-form question on the given documentation:\n\nQuestion: Which of the following statements is true about the proposed method for controller design on manifolds described in the paper?\n\nA) The method embeds the state-space manifold M into a higher dimensional Euclidean space R^n, extends the dynamics to R^n, and adds stability to M outside of M in the ambient space.\n\nB) The method designs linear controllers directly on the manifold M using only local coordinate charts.\n\nC) The method approximates the manifold M by a linear tangent space and designs controllers using linearization. \n\nD) The method discretizes the manifold M into a graph and designs controllers for the graph topology.\n\nCorrect Answer: A\n\nExplanation: \nOption A summarizes the key idea of the proposed method - embedding the manifold M into the Euclidean ambient space R^n, extending the dynamics to R^n, and modifying the dynamics outside M to add transverse stability. \n\nOption B is incorrect as the method uses the global Cartesian coordinates of the ambient space R^n rather than local charts on M.\n\nOption C is incorrect as the method does not linearize the dynamics on the manifold. \n\nOption D is unrelated to the method described in the paper."}, "58": {"documentation": {"title": "Warwick Image Forensics Dataset for Device Fingerprinting In Multimedia\n  Forensics", "source": "Yijun Quan, Chang-Tsun Li, Yujue Zhou and Li Li", "docs_id": "2004.10469", "section": ["cs.CV", "cs.CR", "cs.MM", "eess.IV"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Warwick Image Forensics Dataset for Device Fingerprinting In Multimedia\n  Forensics. Device fingerprints like sensor pattern noise (SPN) are widely used for provenance analysis and image authentication. Over the past few years, the rapid advancement in digital photography has greatly reshaped the pipeline of image capturing process on consumer-level mobile devices. The flexibility of camera parameter settings and the emergence of multi-frame photography algorithms, especially high dynamic range (HDR) imaging, bring new challenges to device fingerprinting. The subsequent study on these topics requires a new purposefully built image dataset. In this paper, we present the Warwick Image Forensics Dataset, an image dataset of more than 58,600 images captured using 14 digital cameras with various exposure settings. Special attention to the exposure settings allows the images to be adopted by different multi-frame computational photography algorithms and for subsequent device fingerprinting. The dataset is released as an open-source, free for use for the digital forensic community."}, "answer": " Question: What does the Warwick Image Forensics Dataset focus on capturing images of?\n\nA) Images captured at different ISO settings {candidate A}  \n\nB) Images captured with different cameras {candidate B}\n\nC) Images captured at various exposure settings {candidate C} \n\nD) Images captured in RAW format {candidate D}\n\nCorrect Answer: C {correct answer}\n\nExplanation: According to the documentation, the Warwick Image Forensics Dataset focuses on capturing images using 14 digital cameras with various exposure settings. The variety of exposure settings allows the images to be used for device fingerprinting and multi-frame computational photography algorithms."}, "59": {"documentation": {"title": "Cube Sampled K-Prototype Clustering for Featured Data", "source": "Seemandhar Jain, Aditya A. Shastri, Kapil Ahuja, Yann Busnel, and\n  Navneet Pratap Singh", "docs_id": "2108.10262", "section": ["cs.LG"], "start_character": "N/A", "end_character": "N/A", "date": "N/A", "text": "Cube Sampled K-Prototype Clustering for Featured Data. Clustering large amount of data is becoming increasingly important in the current times. Due to the large sizes of data, clustering algorithm often take too much time. Sampling this data before clustering is commonly used to reduce this time. In this work, we propose a probabilistic sampling technique called cube sampling along with K-Prototype clustering. Cube sampling is used because of its accurate sample selection. K-Prototype is most frequently used clustering algorithm when the data is numerical as well as categorical (very common in today's time). The novelty of this work is in obtaining the crucial inclusion probabilities for cube sampling using Principal Component Analysis (PCA). Experiments on multiple datasets from the UCI repository demonstrate that cube sampled K-Prototype algorithm gives the best clustering accuracy among similarly sampled other popular clustering algorithms (K-Means, Hierarchical Clustering (HC), Spectral Clustering (SC)). When compared with unsampled K-Prototype, K-Means, HC and SC, it still has the best accuracy with the added advantage of reduced computational complexity (due to reduced data size)."}, "answer": " Here is a 4-option multiple choice question with explanations for the given documentation:\n\nQuestion: Which of the following statements is true about the cube sampled K-Prototype clustering algorithm proposed in the paper?\n\nA) It uses cube sampling to reduce computational complexity and K-Prototype for clustering categorical data. The inclusion probabilities for cube sampling are obtained using K-Means algorithm.\n\nB) It uses random sampling to reduce data size and K-Prototype for clustering numerical data. The inclusion probabilities for random sampling are obtained using Principal Component Analysis. \n\nC) It uses cube sampling to reduce data size and K-Prototype for clustering mixed data. The inclusion probabilities for cube sampling are obtained using Principal Component Analysis.\n\nD) It uses stratified sampling to reduce computational time and K-Means for clustering categorical data. The stratification is done using Principal Component Analysis.\n\nCorrect Answer: C\n\nExplanations:\n- Option A is incorrect as the inclusion probabilities are obtained using PCA, not K-Means. \n- Option B is incorrect as K-Prototype is used for clustering mixed data, not just numerical data. Also, cube sampling is used, not random sampling.\n- Option C is correct as it mentions cube sampling, PCA for inclusion probabilities and use of K-Prototype for mixed data.\n- Option D is incorrect as stratified sampling and K-Means are not used in the proposed method."}}